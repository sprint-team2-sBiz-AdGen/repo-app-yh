# GPT í†µí•© ë°œí‘œìë£Œ

## ğŸ“‹ ê°œìš”

**ê¸°ëŠ¥ëª…**: GPT (Generative Pre-trained Transformer) í†µí•©

**ëª©ì **: í…ìŠ¤íŠ¸ ìƒì„± ë° ë³€í™˜ì„ ìœ„í•œ OpenAI GPT API í†µí•©

**í•µì‹¬ ê°€ì¹˜**: 
- ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìƒì„± ì‘ì—… ì§€ì› (ë²ˆì—­, ìƒì„±, ë³€í™˜)
- ì™„ì „í•œ LLM í˜¸ì¶œ ì¶”ì 
- í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ë¹„ìš© ê´€ë¦¬
- ì¸ìŠ¤íƒ€ê·¸ë¨ ìµœì í™” ì½˜í…ì¸  ìƒì„±

---

## ğŸ¯ ëª©ì 

### ì˜ì–´ â†’ í•œê¸€ ë³€í™˜
- **ëª©ì **: ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ë¥¼ í•œê¸€ë¡œ ë³€í™˜
- **í™œìš©**: ê´‘ê³ ë¬¸êµ¬ì˜ í•œêµ­ì–´ ë²„ì „ ìƒì„±
- **ì¶œë ¥**: í•œê¸€ ê´‘ê³ ë¬¸êµ¬, LLM Trace ID

### ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±
- **ëª©ì **: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ìµœì í™”ëœ í”¼ë“œ ê¸€ ìƒì„±
- **í™œìš©**: SNS ë§ˆì¼€íŒ… ì½˜í…ì¸  ìë™ ìƒì„±
- **ì¶œë ¥**: ì¸ìŠ¤íƒ€ê·¸ë¨ ê´‘ê³ ë¬¸êµ¬, í•´ì‹œíƒœê·¸

### ê´‘ê³ ë¬¸êµ¬ ìƒì„± (í–¥í›„ í™•ì¥)
- **ëª©ì **: ì œí’ˆ ì„¤ëª…ê³¼ í†¤&ìŠ¤íƒ€ì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ê´‘ê³ ë¬¸êµ¬ ìƒì„±
- **í™œìš©**: ì´ˆê¸° ê´‘ê³ ë¬¸êµ¬ ìë™ ìƒì„±
- **ì¶œë ¥**: ì˜ì–´ ê´‘ê³ ë¬¸êµ¬

---

## ğŸ”§ ì£¼ìš” íŠ¹ì§•

### 1. ì™„ì „í•œ LLM ì¶”ì 
- **ëª¨ë“  í˜¸ì¶œ ì €ì¥**: `llm_traces` í…Œì´ë¸”ì— ëª¨ë“  GPT í˜¸ì¶œ ì €ì¥
- **ìš”ì²­/ì‘ë‹µ ì €ì¥**: JSONB í˜•ì‹ìœ¼ë¡œ ì™„ì „í•œ ì¶”ì 
- **í† í° ì‚¬ìš©ëŸ‰**: prompt_tokens, completion_tokens, total_tokens ì¶”ì 

### 2. í† í° ëª¨ë‹ˆí„°ë§
- **ë¹„ìš© ê´€ë¦¬**: í† í° ì‚¬ìš©ëŸ‰ìœ¼ë¡œ API ë¹„ìš© ì¶”ì •
- **ì‚¬ìš©ëŸ‰ ë¶„ì„**: ì‘ì—…ë³„, ëª¨ë¸ë³„ í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„
- **ìµœì í™”**: í† í° ì‚¬ìš©ëŸ‰ ìµœì†Œí™”ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìµœì í™”

### 3. LLM ëª¨ë¸ ê´€ë¦¬
- **ëª¨ë¸ ì •ë³´ ì €ì¥**: `llm_models` í…Œì´ë¸”ì— ëª¨ë¸ ì •ë³´ ì €ì¥
- **í™œì„± ëª¨ë¸ ì¶”ì **: í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì¶”ì 
- **ëª¨ë¸ë³„ í†µê³„**: ëª¨ë¸ë³„ ì„±ëŠ¥ ë° ë¹„ìš© ë¶„ì„

### 4. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„
- **ì•ˆì •ì ì¸ ì²˜ë¦¬**: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì ì ˆí•œ ì—ëŸ¬ ì²˜ë¦¬
- **ë¡œê¹…**: ìƒì„¸í•œ ë¡œê·¸ë¡œ ë””ë²„ê¹… ìš©ì´
- **ì¬ì‹œë„ ë¡œì§**: ì¼ì‹œì  ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„ (í–¥í›„ í™•ì¥)

---

## ğŸ“ êµ¬í˜„ ìœ„ì¹˜

### ì„œë¹„ìŠ¤ ë ˆì´ì–´
- `services/gpt_service.py`: GPT ì„œë¹„ìŠ¤ ë¡œì§ (API í˜¸ì¶œ, í”„ë¡¬í”„íŠ¸ êµ¬ì„±)

### API ì—”ë“œí¬ì¸íŠ¸
- `routers/gpt.py`: GPT API ì—”ë“œí¬ì¸íŠ¸ (`/api/yh/gpt/eng-to-kor`)
- `routers/instagram_feed.py`: ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„± (`/api/yh/instagram/feed`)

### ë°ì´í„°ë² ì´ìŠ¤
- `llm_traces` í…Œì´ë¸”: ëª¨ë“  GPT í˜¸ì¶œ ì¶”ì  ë° ì €ì¥
- `llm_models` í…Œì´ë¸”: LLM ëª¨ë¸ ì •ë³´ ì €ì¥
- `txt_ad_copy_generations` í…Œì´ë¸”: ê´‘ê³ ë¬¸êµ¬ ìƒì„± ê²°ê³¼ ì €ì¥
- `instagram_feeds` í…Œì´ë¸”: ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ì €ì¥

---

## ğŸ’» êµ¬í˜„ ì½”ë“œ

### 1. GPT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

**íŒŒì¼**: `services/gpt_service.py`

```python
from openai import OpenAI
from config import GPT_API_KEY, GPT_MODEL_NAME, GPT_MAX_TOKENS

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
_client: Optional[OpenAI] = None

def get_gpt_client() -> OpenAI:
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global _client
    if _client is None:
        api_key = GPT_API_KEY
        if not api_key:
            raise ValueError(
                "OPENAPI_KEY ë˜ëŠ” GPT_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                ".env íŒŒì¼ì— OPENAPI_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )
        _client = OpenAI(api_key=api_key)
    return _client
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ì‹±ê¸€í†¤ íŒ¨í„´**: í´ë¼ì´ì–¸íŠ¸ë¥¼ í•œ ë²ˆë§Œ ì´ˆê¸°í™”
- **ì—ëŸ¬ ì²˜ë¦¬**: API í‚¤ê°€ ì—†ìœ¼ë©´ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€

---

### 2. ì˜ì–´ â†’ í•œê¸€ ë³€í™˜

**íŒŒì¼**: `services/gpt_service.py`

```python
def translate_eng_to_kor(ad_copy_eng: str) -> Dict[str, Any]:
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ë¥¼ í•œê¸€ë¡œ ë³€í™˜
    
    Args:
        ad_copy_eng: ì˜ì–´ ê´‘ê³ ë¬¸êµ¬
    
    Returns:
        Dict[str, Any]: {
            "ad_copy_kor": í•œê¸€ ê´‘ê³ ë¬¸êµ¬,
            "prompt_used": ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸,
            "latency_ms": API í˜¸ì¶œ ì†Œìš” ì‹œê°„ (ë°€ë¦¬ì´ˆ),
            "token_usage": í† í° ì‚¬ìš©ëŸ‰ ì •ë³´,
            "gpt_response_raw": GPT API ì›ë³¸ ì‘ë‹µ (JSONB í˜•ì‹)
        }
    """
    try:
        client = get_gpt_client()
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """You are an expert translator specializing in translating English ad copy to Korean.
Your task is to translate English advertising copy into natural, engaging Korean that:
1. Maintains the original meaning and intent
2. Sounds natural and authentic in Korean
3. Preserves the marketing tone and style
4. Is appropriate for Korean audiences
5. Keeps the same length and impact as the original

Return only the Korean translation without any additional explanation or formatting."""
        
        user_prompt = f"""Translate the following English ad copy to Korean:

{ad_copy_eng}

Please provide only the Korean translation, maintaining the original tone and style."""

        # GPT API í˜¸ì¶œ (latency ì¸¡ì •)
        start_time = time.time()
        response = client.chat.completions.create(
            model=GPT_MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=GPT_MAX_TOKENS,
            temperature=0.3,  # ë²ˆì—­ì€ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
        )
        latency_ms = (time.time() - start_time) * 1000
        
        # ì‘ë‹µ íŒŒì‹±
        response_text = response.choices[0].message.content.strip()
        ad_copy_kor = response_text
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        usage = response.usage
        prompt_tokens = usage.prompt_tokens if usage else None
        completion_tokens = usage.completion_tokens if usage else None
        total_tokens = usage.total_tokens if usage else None
        
        # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
        if usage:
            logger.info(
                f"Token usage - prompt: {prompt_tokens}, "
                f"completion: {completion_tokens}, total: {total_tokens}"
            )
        else:
            logger.warning("OpenAI API ì‘ë‹µì— usage ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë””ë²„ê¹…ìš©)
        prompt_used = f"{system_prompt}\n\n{user_prompt}"
        
        # GPT ì‘ë‹µ ì›ë³¸ ì €ì¥
        gpt_response_raw = {
            "model": response.model,
            "choices": [
                {
                    "message": {
                        "role": choice.message.role,
                        "content": choice.message.content
                    },
                    "finish_reason": choice.finish_reason
                }
                for choice in response.choices
            ],
            "usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            } if usage else None
        }
        
        return {
            "ad_copy_kor": ad_copy_kor,
            "prompt_used": prompt_used,
            "latency_ms": latency_ms,
            "token_usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            } if usage else None,
            "gpt_response_raw": gpt_response_raw
        }
    except Exception as e:
        logger.error(f"GPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        raise
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  í˜¸ì¶œì„ `llm_traces`ì— ì €ì¥
- **í† í° ëª¨ë‹ˆí„°ë§**: ë¹„ìš© ê´€ë¦¬ ë° ìµœì í™”
- **ì—ëŸ¬ ì²˜ë¦¬**: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì ì ˆí•œ ì²˜ë¦¬

---

### 3. ì˜ì–´ â†’ í•œê¸€ ë³€í™˜ API ì—”ë“œí¬ì¸íŠ¸

**íŒŒì¼**: `routers/gpt.py`

```python
@router.post("/eng-to-kor", response_model=EngToKorOut)
def eng_to_kor(body: EngToKorIn, db: Session = Depends(get_db)):
    """
    ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ë¥¼ í•œê¸€ë¡œ ë³€í™˜
    
    Args:
        body: EngToKorIn ëª¨ë¸
            - job_id: Job ID
            - tenant_id: Tenant ID
    
    Returns:
        EngToKorOut:
            - job_id: Job ID
            - llm_trace_id: LLM Trace ID
            - ad_copy_gen_id: Ad Copy Generation ID
            - ad_copy_kor: í•œê¸€ ê´‘ê³ ë¬¸êµ¬
            - status: ìƒíƒœ ('done' ë˜ëŠ” 'failed')
    """
    # Step 1: Job ì¡°íšŒ ë° ê²€ì¦
    job = db.query(Job).filter(Job.job_id == body.job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail=f"Job not found: {body.job_id}")
    
    # Step 2: txt_ad_copy_generationsì—ì„œ ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ ì¡°íšŒ
    # refined_ad_copy_eng ìš°ì„ , ì—†ìœ¼ë©´ ad_copy_eng ì‚¬ìš©
    ad_copy_gen = db.execute(
        text("""
            SELECT 
                ad_copy_gen_id,
                COALESCE(refined_ad_copy_eng, ad_copy_eng) AS ad_copy_eng
            FROM txt_ad_copy_generations
            WHERE job_id = :job_id
              AND (
                  (generation_stage = 'refined_ad_copy' AND refined_ad_copy_eng IS NOT NULL)
                  OR (generation_stage = 'ad_copy_eng' AND ad_copy_eng IS NOT NULL)
              )
              AND status = 'done'
            ORDER BY 
                CASE generation_stage
                    WHEN 'refined_ad_copy' THEN 1
                    WHEN 'ad_copy_eng' THEN 2
                END,
                created_at DESC
            LIMIT 1
        """),
        {"job_id": body.job_id}
    ).first()
    
    if not ad_copy_gen or not ad_copy_gen.ad_copy_eng:
        raise HTTPException(
            status_code=400,
            detail=f"English ad copy not found for job_id: {body.job_id}"
        )
    
    ad_copy_eng = ad_copy_gen.ad_copy_eng
    
    # Step 3: LLM ëª¨ë¸ ì¡°íšŒ
    llm_model = db.query(LLMModel).filter(
        LLMModel.model_name == GPT_MODEL_NAME,
        LLMModel.is_active == 'true'
    ).first()
    
    if not llm_model:
        logger.warning(f"âš ï¸ LLM ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {GPT_MODEL_NAME}")
        llm_model_id = None
    else:
        llm_model_id = llm_model.llm_model_id
    
    # Step 4: GPT API í˜¸ì¶œ: ì˜ì–´ â†’ í•œê¸€ ë³€í™˜
    try:
        result = translate_eng_to_kor(ad_copy_eng=ad_copy_eng)
    except Exception as e:
        logger.error(f"GPT API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Translation failed: {str(e)}")
    
    # Step 5: llm_tracesì— ì €ì¥
    llm_trace_id = uuid.uuid4()
    db.execute(
        text("""
            INSERT INTO llm_traces (
                llm_trace_id, job_id, llm_model_id,
                provider, operation_type,
                request, response,
                prompt_tokens, completion_tokens, total_tokens,
                token_usage, latency_ms,
                created_at, updated_at
            ) VALUES (
                :llm_trace_id, :job_id, :llm_model_id,
                'gpt', 'eng_to_kor',
                CAST(:request AS jsonb), CAST(:response AS jsonb),
                :prompt_tokens, :completion_tokens, :total_tokens,
                CAST(:token_usage AS jsonb), :latency_ms,
                CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
            )
        """),
        {
            "llm_trace_id": llm_trace_id,
            "job_id": body.job_id,
            "llm_model_id": llm_model_id,
            "request": json.dumps({"ad_copy_eng": ad_copy_eng}),
            "response": json.dumps({"ad_copy_kor": result["ad_copy_kor"]}),
            "prompt_tokens": result["token_usage"]["prompt_tokens"] if result["token_usage"] else None,
            "completion_tokens": result["token_usage"]["completion_tokens"] if result["token_usage"] else None,
            "total_tokens": result["token_usage"]["total_tokens"] if result["token_usage"] else None,
            "token_usage": json.dumps(result["token_usage"]) if result["token_usage"] else None,
            "latency_ms": result["latency_ms"]
        }
    )
    
    # Step 6: txt_ad_copy_generations ë ˆì½”ë“œ ìƒì„±/ì—…ë°ì´íŠ¸
    ad_copy_gen_id = uuid.uuid4()
    db.execute(
        text("""
            INSERT INTO txt_ad_copy_generations (
                ad_copy_gen_id, job_id, llm_trace_id,
                generation_stage, ad_copy_kor, status,
                created_at, updated_at
            ) VALUES (
                :ad_copy_gen_id, :job_id, :llm_trace_id,
                'eng_to_kor', :ad_copy_kor, 'done',
                CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
            )
        """),
        {
            "ad_copy_gen_id": ad_copy_gen_id,
            "job_id": body.job_id,
            "llm_trace_id": llm_trace_id,
            "ad_copy_kor": result["ad_copy_kor"]
        }
    )
    
    # Step 7: Job ìƒíƒœ ì—…ë°ì´íŠ¸
    db.execute(
        text("""
            UPDATE jobs
            SET status = 'done',
                current_step = 'ad_copy_gen_kor',
                updated_at = CURRENT_TIMESTAMP
            WHERE job_id = :job_id
        """),
        {"job_id": body.job_id}
    )
    
    db.commit()
    
    return EngToKorOut(
        job_id=body.job_id,
        llm_trace_id=str(llm_trace_id),
        ad_copy_gen_id=str(ad_copy_gen_id),
        ad_copy_kor=result["ad_copy_kor"],
        status="done"
    )
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  í˜¸ì¶œì„ `llm_traces`ì— ì €ì¥
- **í† í° ëª¨ë‹ˆí„°ë§**: ë¹„ìš© ê´€ë¦¬ ë° ìµœì í™”
- **ìƒíƒœ ê´€ë¦¬**: Job ìƒíƒœ ìë™ ì—…ë°ì´íŠ¸

---

### 4. ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±

**íŒŒì¼**: `services/gpt_service.py`

```python
def generate_instagram_feed(
    refined_ad_copy_eng: str,
    tone_style: str,
    product_description: str,
    store_information: str,
    gpt_prompt: str
) -> Dict[str, Any]:
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ ìƒì„±
    
    Args:
        refined_ad_copy_eng: ì¡°ì •ëœ ê´‘ê³ ë¬¸êµ¬ (ì˜ì–´)
        tone_style: í†¤ & ìŠ¤íƒ€ì¼
        product_description: ì œí’ˆ ì„¤ëª…
        store_information: ìŠ¤í† ì–´ ì •ë³´
        gpt_prompt: GPT í”„ë¡¬í”„íŠ¸
    
    Returns:
        Dict[str, Any]: {
            "instagram_ad_copy": ì¸ìŠ¤íƒ€ê·¸ë¨ ê´‘ê³ ë¬¸êµ¬,
            "hashtags": í•´ì‹œíƒœê·¸ ë¬¸ìì—´,
            "prompt_used": ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸,
            "latency_ms": API í˜¸ì¶œ ì†Œìš” ì‹œê°„ (ë°€ë¦¬ì´ˆ),
            "token_usage": í† í° ì‚¬ìš©ëŸ‰ ì •ë³´,
            "gpt_response_raw": GPT API ì›ë³¸ ì‘ë‹µ (JSONB í˜•ì‹)
        }
    """
    try:
        client = get_gpt_client()
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """You are an expert Instagram content creator specializing in creating engaging ad copy and relevant hashtags for Korean audiences. 
Your task is to create compelling Instagram feed posts in Korean that:
1. Are engaging and authentic
2. Match the brand's tone and style
3. MUST include 5-10 relevant hashtags (this is REQUIRED, not optional)
4. Are optimized for Instagram's format
5. Encourage user engagement

IMPORTANT: You MUST always include hashtags in your response. The hashtags field must never be empty.

Format your response as JSON with the following structure:
{
    "instagram_ad_copy": "The main Instagram post text in Korean (without hashtags in the main text)",
    "hashtags": "#hashtag1 #hashtag2 #hashtag3 #hashtag4 #hashtag5 ..."
}

Rules for hashtags:
- MUST include 5-10 hashtags
- Each hashtag must start with # symbol
- Separate hashtags with a single space
- Use Korean hashtags relevant to the product, store, and Korean market
- Include popular Korean food/restaurant hashtags like #ë§›ì§‘ #ë§›ìŠ¤íƒ€ê·¸ë¨ #ë¨¹ìŠ¤íƒ€ê·¸ë¨ #í‘¸ë“œìŠ¤íƒ€ê·¸ë¨
- Include location-based hashtags if store information is provided
- Hashtags should be in Korean (í•œê¸€)"""
        
        user_prompt = f"""Create an Instagram feed post in Korean based on the following information:

Ad Copy (English): {refined_ad_copy_eng}
Tone & Style: {tone_style}
Product Description: {product_description}
Store Information: {store_information}

Custom Prompt: {gpt_prompt}

Please create an engaging Instagram post in Korean that includes:
1. A compelling main text (without hashtags)
2. 5-10 relevant Korean hashtags

Return your response as JSON with "instagram_ad_copy" and "hashtags" fields."""

        # GPT API í˜¸ì¶œ
        start_time = time.time()
        response = client.chat.completions.create(
            model=GPT_MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=GPT_MAX_TOKENS,
            temperature=0.7,  # ì°½ì˜ì„±ì„ ìœ„í•´ ì¤‘ê°„ temperature ì‚¬ìš©
            response_format={"type": "json_object"}  # JSON í˜•ì‹ ê°•ì œ
        )
        latency_ms = (time.time() - start_time) * 1000
        
        # ì‘ë‹µ íŒŒì‹±
        response_text = response.choices[0].message.content.strip()
        response_json = json.loads(response_text)
        
        instagram_ad_copy = response_json.get("instagram_ad_copy", "")
        hashtags = response_json.get("hashtags", "")
        
        # í•´ì‹œíƒœê·¸ ê²€ì¦
        if not hashtags:
            logger.warning("âš ï¸ GPT ì‘ë‹µì— í•´ì‹œíƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í•´ì‹œíƒœê·¸ ì¶”ê°€.")
            hashtags = "#ë§›ì§‘ #ë§›ìŠ¤íƒ€ê·¸ë¨ #ë¨¹ìŠ¤íƒ€ê·¸ë¨ #í‘¸ë“œìŠ¤íƒ€ê·¸ë¨ #ìŒì‹ìŠ¤íƒ€ê·¸ë¨"
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        usage = response.usage
        prompt_tokens = usage.prompt_tokens if usage else None
        completion_tokens = usage.completion_tokens if usage else None
        total_tokens = usage.total_tokens if usage else None
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë””ë²„ê¹…ìš©)
        prompt_used = f"{system_prompt}\n\n{user_prompt}"
        
        # GPT ì‘ë‹µ ì›ë³¸ ì €ì¥
        gpt_response_raw = {
            "model": response.model,
            "choices": [
                {
                    "message": {
                        "role": choice.message.role,
                        "content": choice.message.content
                    },
                    "finish_reason": choice.finish_reason
                }
                for choice in response.choices
            ],
            "usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            } if usage else None
        }
        
        return {
            "instagram_ad_copy": instagram_ad_copy,
            "hashtags": hashtags,
            "prompt_used": prompt_used,
            "latency_ms": latency_ms,
            "token_usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            } if usage else None,
            "gpt_response_raw": gpt_response_raw
        }
    except Exception as e:
        logger.error(f"GPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        raise
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **SNS ìµœì í™”**: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ìƒì„±
- **í•´ì‹œíƒœê·¸ ìë™ ìƒì„±**: ê´€ë ¨ í•´ì‹œíƒœê·¸ ìë™ ì¶”ì¶œ
- **JSON í˜•ì‹ ê°•ì œ**: êµ¬ì¡°í™”ëœ ì‘ë‹µ ë³´ì¥

---

### 5. ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„± API ì—”ë“œí¬ì¸íŠ¸

**íŒŒì¼**: `routers/instagram_feed.py`

```python
@router.post("/feed", response_model=InstagramFeedOut)
def create_instagram_feed(body: InstagramFeedIn, db: Session = Depends(get_db)):
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ ìƒì„± ë° DB ì €ì¥
    
    Args:
        body: InstagramFeedIn ëª¨ë¸
            - job_id: Job ID
            - tenant_id: Tenant ID
            - gpt_prompt: GPT í”„ë¡¬í”„íŠ¸
    
    Returns:
        InstagramFeedOut:
            - instagram_feed_id: ìƒì„±ëœ í”¼ë“œ ID
            - instagram_ad_copy: ì¸ìŠ¤íƒ€ê·¸ë¨ ê´‘ê³ ë¬¸êµ¬
            - hashtags: í•´ì‹œíƒœê·¸
    """
    # Step 1: Job ì¡°íšŒ ë° ê²€ì¦
    job = db.query(Job).filter(Job.job_id == body.job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail=f"Job not found: {body.job_id}")
    
    # Step 2: txt_ad_copy_generationsì—ì„œ í•œê¸€ ê´‘ê³ ë¬¸êµ¬ ì¡°íšŒ
    ad_copy_kor_row = db.execute(
        text("""
            SELECT ad_copy_kor
            FROM txt_ad_copy_generations
            WHERE job_id = :job_id
              AND generation_stage = 'eng_to_kor'
              AND status = 'done'
            ORDER BY created_at DESC
            LIMIT 1
        """),
        {"job_id": body.job_id}
    ).first()
    
    ad_copy_kor = ad_copy_kor_row.ad_copy_kor if ad_copy_kor_row else None
    
    # Step 3: txt_ad_copy_generationsì—ì„œ refined_ad_copy_eng ì¡°íšŒ
    refined_ad_copy_row = db.execute(
        text("""
            SELECT COALESCE(refined_ad_copy_eng, ad_copy_eng) AS refined_ad_copy_eng
            FROM txt_ad_copy_generations
            WHERE job_id = :job_id
              AND (
                  (generation_stage = 'refined_ad_copy' AND refined_ad_copy_eng IS NOT NULL)
                  OR (generation_stage = 'ad_copy_eng' AND ad_copy_eng IS NOT NULL)
              )
              AND status = 'done'
            ORDER BY 
                CASE generation_stage
                    WHEN 'refined_ad_copy' THEN 1
                    WHEN 'ad_copy_eng' THEN 2
                END,
                created_at DESC
            LIMIT 1
        """),
        {"job_id": body.job_id}
    ).first()
    
    refined_ad_copy_eng = refined_ad_copy_row.refined_ad_copy_eng if refined_ad_copy_row else None
    if not refined_ad_copy_eng:
        raise HTTPException(
            status_code=400,
            detail=f"English ad copy not found for job_id: {body.job_id}"
        )
    
    # Step 4: job_inputsì—ì„œ tone_style, product_description ì¡°íšŒ
    job_input = db.query(JobInput).filter(JobInput.job_id == body.job_id).first()
    if not job_input:
        raise HTTPException(status_code=404, detail=f"JobInput not found: {body.job_id}")
    
    product_description = job_input.desc_kor if job_input.desc_kor else ""
    tone_style = "default"  # TODO: tone_styles í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
    
    # Step 5: stores í…Œì´ë¸”ì—ì„œ ìŠ¤í† ì–´ ì •ë³´ ì¡°íšŒ
    store_information = ""  # TODO: stores í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
    
    # Step 6: GPT API í˜¸ì¶œ
    try:
        result = generate_instagram_feed(
            refined_ad_copy_eng=refined_ad_copy_eng,
            tone_style=tone_style,
            product_description=product_description,
            store_information=store_information,
            gpt_prompt=body.gpt_prompt
        )
    except Exception as e:
        logger.error(f"GPT API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Feed generation failed: {str(e)}")
    
    # Step 7: LLM ëª¨ë¸ ì¡°íšŒ
    llm_model = db.query(LLMModel).filter(
        LLMModel.model_name == GPT_MODEL_NAME,
        LLMModel.is_active == 'true'
    ).first()
    llm_model_id = llm_model.llm_model_id if llm_model else None
    
    # Step 8: llm_tracesì— ì €ì¥
    llm_trace_id = uuid.uuid4()
    db.execute(
        text("""
            INSERT INTO llm_traces (
                llm_trace_id, job_id, llm_model_id,
                provider, operation_type,
                request, response,
                prompt_tokens, completion_tokens, total_tokens,
                token_usage, latency_ms,
                created_at, updated_at
            ) VALUES (
                :llm_trace_id, :job_id, :llm_model_id,
                'gpt', 'feed_gen',
                CAST(:request AS jsonb), CAST(:response AS jsonb),
                :prompt_tokens, :completion_tokens, :total_tokens,
                CAST(:token_usage AS jsonb), :latency_ms,
                CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
            )
        """),
        {
            "llm_trace_id": llm_trace_id,
            "job_id": body.job_id,
            "llm_model_id": llm_model_id,
            "request": json.dumps({
                "refined_ad_copy_eng": refined_ad_copy_eng,
                "tone_style": tone_style,
                "product_description": product_description,
                "store_information": store_information,
                "gpt_prompt": body.gpt_prompt
            }),
            "response": json.dumps({
                "instagram_ad_copy": result["instagram_ad_copy"],
                "hashtags": result["hashtags"]
            }),
            "prompt_tokens": result["token_usage"]["prompt_tokens"] if result["token_usage"] else None,
            "completion_tokens": result["token_usage"]["completion_tokens"] if result["token_usage"] else None,
            "total_tokens": result["token_usage"]["total_tokens"] if result["token_usage"] else None,
            "token_usage": json.dumps(result["token_usage"]) if result["token_usage"] else None,
            "latency_ms": result["latency_ms"]
        }
    )
    
    # Step 9: instagram_feedsì— ì €ì¥
    instagram_feed_id = uuid.uuid4()
    db.execute(
        text("""
            INSERT INTO instagram_feeds (
                instagram_feed_id, job_id, llm_trace_id,
                gpt_prompt, ad_copy_kor,
                instagram_ad_copy, hashtags,
                status, created_at, updated_at
            ) VALUES (
                :instagram_feed_id, :job_id, :llm_trace_id,
                :gpt_prompt, :ad_copy_kor,
                :instagram_ad_copy, :hashtags,
                'done', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
            )
        """),
        {
            "instagram_feed_id": instagram_feed_id,
            "job_id": body.job_id,
            "llm_trace_id": llm_trace_id,
            "gpt_prompt": body.gpt_prompt,
            "ad_copy_kor": ad_copy_kor,
            "instagram_ad_copy": result["instagram_ad_copy"],
            "hashtags": result["hashtags"]
        }
    )
    
    # Step 10: Job ìƒíƒœ ì—…ë°ì´íŠ¸
    db.execute(
        text("""
            UPDATE jobs
            SET status = 'done',
                current_step = 'instagram_feed_gen',
                updated_at = CURRENT_TIMESTAMP
            WHERE job_id = :job_id
        """),
        {"job_id": body.job_id}
    )
    
    db.commit()
    
    return InstagramFeedOut(
        instagram_feed_id=str(instagram_feed_id),
        instagram_ad_copy=result["instagram_ad_copy"],
        hashtags=result["hashtags"]
    )
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **SNS ìµœì í™”**: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ìƒì„±
- **í•´ì‹œíƒœê·¸ ìë™ ìƒì„±**: ê´€ë ¨ í•´ì‹œíƒœê·¸ ìë™ ì¶”ì¶œ
- **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  ìƒì„± ê³¼ì • ì¶”ì 

---

## ğŸ”„ íŒŒì´í”„ë¼ì¸ í†µí•©

### ì˜ì–´ â†’ í•œê¸€ ë³€í™˜ íë¦„
```
[iou_eval ì™„ë£Œ (ëª¨ë“  variants)]
  â†“
[ad_copy_gen_kor íŠ¸ë¦¬ê±°]
  â†“
[GPT API í˜¸ì¶œ: ì˜ì–´ â†’ í•œê¸€ ë³€í™˜]
  â†“
[ê²°ê³¼ ì €ì¥ (llm_traces, txt_ad_copy_generations)]
  â†“
[Job ìƒíƒœ ì—…ë°ì´íŠ¸: done]
  â†“
[instagram_feed_gen ìë™ íŠ¸ë¦¬ê±°]
```

### ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„± íë¦„
```
[ad_copy_gen_kor ì™„ë£Œ]
  â†“
[instagram_feed_gen íŠ¸ë¦¬ê±°]
  â†“
[GPT API í˜¸ì¶œ: ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±]
  â†“
[ê²°ê³¼ ì €ì¥ (llm_traces, instagram_feeds)]
  â†“
[Job ìƒíƒœ ì—…ë°ì´íŠ¸: done]
  â†“
[íŒŒì´í”„ë¼ì¸ ì™„ë£Œ]
```

---

## ğŸ“Š ì„±ëŠ¥ ë° í†µê³„

### API ì‘ë‹µ ì‹œê°„
- **ì˜ì–´ â†’ í•œê¸€ ë³€í™˜**: ì•½ 2-5ì´ˆ
- **ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±**: ì•½ 3-7ì´ˆ

### í† í° ì‚¬ìš©ëŸ‰
- **ì˜ì–´ â†’ í•œê¸€ ë³€í™˜**: í‰ê·  200-400 í† í°
- **ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±**: í‰ê·  500-1000 í† í°

### ë¹„ìš© ì¶”ì • (gpt-4o-mini ê¸°ì¤€)
- **ì˜ì–´ â†’ í•œê¸€ ë³€í™˜**: ì•½ $0.0001-0.0002 per request
- **ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±**: ì•½ $0.0003-0.0006 per request

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: í† í° ì‚¬ìš©ëŸ‰ì´ null

**ì¦ìƒ**: `llm_traces` í…Œì´ë¸”ì˜ í† í° ê´€ë ¨ ì»¬ëŸ¼ì´ null

**ì›ì¸**: OpenAI API ì‘ë‹µì— `usage` ì •ë³´ê°€ ì—†ìŒ

**í•´ê²° ë°©ë²•**:
```python
# usage ì •ë³´ í™•ì¸
if response.usage:
    prompt_tokens = response.usage.prompt_tokens
    completion_tokens = response.usage.completion_tokens
    total_tokens = response.usage.total_tokens
else:
    logger.warning("OpenAI API ì‘ë‹µì— usage ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
```

---

### ë¬¸ì œ 2: API í˜¸ì¶œ ì‹¤íŒ¨

**ì¦ìƒ**: OpenAI API í˜¸ì¶œ ì‹¤íŒ¨

**í•´ê²° ë°©ë²•**:
1. API í‚¤ í™•ì¸
   ```bash
   echo $OPENAPI_KEY
   ```
2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
3. Rate limit í™•ì¸
4. ì¬ì‹œë„ ë¡œì§ êµ¬í˜„ (í–¥í›„ í™•ì¥)

---

### ë¬¸ì œ 3: JSON íŒŒì‹± ì˜¤ë¥˜

**ì¦ìƒ**: ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„± ì‹œ JSON íŒŒì‹± ì˜¤ë¥˜

**ì›ì¸**: GPT ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹˜

**í•´ê²° ë°©ë²•**:
1. `response_format={"type": "json_object"}` ì‚¬ìš©
2. íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback ë¡œì§ êµ¬í˜„
3. í”„ë¡¬í”„íŠ¸ì— JSON í˜•ì‹ ëª…ì‹œ

---

### ë¬¸ì œ 4: í•´ì‹œíƒœê·¸ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**: `hashtags` í•„ë“œê°€ ë¹„ì–´ìˆìŒ

**ì›ì¸**: GPTê°€ í•´ì‹œíƒœê·¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ

**í•´ê²° ë°©ë²•**:
1. í”„ë¡¬í”„íŠ¸ì— í•´ì‹œíƒœê·¸ í•„ìˆ˜ ëª…ì‹œ
2. ê¸°ë³¸ í•´ì‹œíƒœê·¸ fallback ì œê³µ
3. í•´ì‹œíƒœê·¸ ê²€ì¦ ë¡œì§ ì¶”ê°€

---

### ë¬¸ì œ 5: ë²ˆì—­ í’ˆì§ˆì´ ë‚®ìŒ

**ì¦ìƒ**: ë²ˆì—­ ê²°ê³¼ê°€ ìì—°ìŠ¤ëŸ½ì§€ ì•ŠìŒ

**í•´ê²° ë°©ë²•**:
1. í”„ë¡¬í”„íŠ¸ ê°œì„ 
2. `temperature` ì¡°ì • (ë‚®ì€ ê°’ìœ¼ë¡œ ì¼ê´€ì„± í–¥ìƒ)
3. Few-shot ì˜ˆì œ ì¶”ê°€

---

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

### ì¥ì 
- âœ… ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìƒì„± ì‘ì—… ì§€ì›
- âœ… ì™„ì „í•œ LLM í˜¸ì¶œ ì¶”ì 
- âœ… í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- âœ… ì¸ìŠ¤íƒ€ê·¸ë¨ ìµœì í™” ì½˜í…ì¸  ìƒì„±

### í™œìš© ì‚¬ë¡€
- ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ â†’ í•œê¸€ ë³€í™˜
- ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ ìë™ ìƒì„±
- í•´ì‹œíƒœê·¸ ìë™ ìƒì„±

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- `DOCS_JS_PART_IMPLEMENTATION.md`: JS íŒŒíŠ¸ êµ¬í˜„ ê°€ì´ë“œ
- `DOCS_YH_PART_IMPLEMENTATION.md`: YH íŒŒíŠ¸ êµ¬í˜„ ê°€ì´ë“œ
- `presentation/05_TEXT_GENERATION_TRANSLATION.md`: í…ìŠ¤íŠ¸ ìƒì„± ë° ë²ˆì—­ ë°œí‘œìë£Œ

---

**ì‘ì„±ì¼**: 2025-12-02  
**ì‘ì„±ì**: LEEYH205  
**ë²„ì „**: 1.0.0



