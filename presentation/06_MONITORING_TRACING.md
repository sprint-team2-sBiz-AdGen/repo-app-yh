# ëª¨ë‹ˆí„°ë§ ë° ì¶”ì  ë°œí‘œìë£Œ

## ğŸ“‹ ê°œìš”

**ê¸°ëŠ¥ëª…**: ì™„ì „í•œ ëª¨ë‹ˆí„°ë§ ë° ì¶”ì  ì‹œìŠ¤í…œ

**ëª©ì **: ëª¨ë“  LLM í˜¸ì¶œê³¼ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë¥¼ ì¶”ì í•˜ì—¬ ë¹„ìš©, ì„±ëŠ¥, í’ˆì§ˆì„ ëª¨ë‹ˆí„°ë§

**í•µì‹¬ ê°€ì¹˜**: 
- ì™„ì „í•œ í˜¸ì¶œ ì¶”ì 
- ë¹„ìš© ëª¨ë‹ˆí„°ë§
- ì„±ëŠ¥ ë¶„ì„
- ì¥ì•  ë³µêµ¬ ì§€ì›

---

## ğŸ¯ ëª©ì 

### ë¬¸ì œ í•´ê²°
- **ë¹„ìš© ê´€ë¦¬**: LLM API í˜¸ì¶œ ë¹„ìš© ì¶”ì  ì–´ë ¤ì›€
- **ì„±ëŠ¥ ë¶„ì„**: ì–´ë–¤ ë‹¨ê³„ê°€ ëŠë¦°ì§€ íŒŒì•… ì–´ë ¤ì›€
- **ì¥ì•  ì¶”ì **: ë¬¸ì œ ë°œìƒ ì‹œ ì›ì¸ íŒŒì•… ì–´ë ¤ì›€
- **í’ˆì§ˆ ê´€ë¦¬**: ìƒì„±ëœ ì½˜í…ì¸ ì˜ í’ˆì§ˆ ì¶”ì  ì–´ë ¤ì›€

### í•´ê²° ë°©ì•ˆ
- **LLM ì¶”ì  ì‹œìŠ¤í…œ**: ëª¨ë“  LLM í˜¸ì¶œì„ `llm_traces`ì— ì €ì¥
- **Job ìƒíƒœ ê´€ë¦¬**: íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒí™©ì„ ì„¸ë°€í•˜ê²Œ ì¶”ì 
- **Variantë³„ ì¶”ì **: ê° Variantì˜ ë…ë¦½ì  ì§„í–‰ ì¶”ì 
- **ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜**: ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ ë° ë³µêµ¬

---

## âœ¨ ì£¼ìš” íŠ¹ì§•

### 1. LLM ì¶”ì  ì‹œìŠ¤í…œ
- **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  LLM API í˜¸ì¶œ ì¶”ì 
- **í† í° ì‚¬ìš©ëŸ‰**: prompt_tokens, completion_tokens, total_tokens
- **ì§€ì—° ì‹œê°„**: latency_msë¡œ ì„±ëŠ¥ ì¸¡ì •
- **ëª¨ë¸ ì •ë³´**: ì‚¬ìš©ëœ LLM ëª¨ë¸ ì¶”ì 
- **ì‘ì—… ìœ í˜•**: operation_typeìœ¼ë¡œ ì‘ì—… ë¶„ë¥˜

### 2. Job ë° Variant ìƒíƒœ ê´€ë¦¬
- **Job ë ˆë²¨ ìƒíƒœ**: ì „ì²´ Jobì˜ ì§„í–‰ ìƒí™© ì¶”ì 
- **Variantë³„ ì¶”ì **: ê° Variantì˜ ë…ë¦½ì  ì§„í–‰ ì¶”ì 
- **ë‹¨ê³„ë³„ ìƒíƒœ**: current_stepìœ¼ë¡œ í˜„ì¬ ë‹¨ê³„ ì¶”ì 
- **ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜**: retry_countë¡œ ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì 

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### ì¶”ì  ì‹œìŠ¤í…œ êµ¬ì¡°

```
[LLM API í˜¸ì¶œ]
GPT API í˜¸ì¶œ
  â†“
[í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ]
response.usageì—ì„œ ì¶”ì¶œ
  â†“
[LLM Trace ì €ì¥]
llm_traces í…Œì´ë¸”ì— ì €ì¥
  â†“
[ìƒíƒœ ì—…ë°ì´íŠ¸]
jobs/jobs_variants ìƒíƒœ ì—…ë°ì´íŠ¸
  â†“
[ëª¨ë‹ˆí„°ë§]
ë¹„ìš©, ì„±ëŠ¥, í’ˆì§ˆ ë¶„ì„
```

---

## ğŸ’» êµ¬í˜„ ì½”ë“œ

### 1. LLM Traces í…Œì´ë¸” êµ¬ì¡°

**íŒŒì¼**: `db/init/01_schema.sql`

```sql
CREATE TABLE llm_traces (
    llm_trace_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    job_id UUID REFERENCES jobs(job_id) ON DELETE SET NULL,
    provider VARCHAR(255),  -- 'gpt', 'anthropic', etc.
    llm_model_id UUID REFERENCES llm_models(llm_model_id) ON DELETE SET NULL,
    tone_style_id UUID REFERENCES tone_styles(tone_style_id) ON DELETE SET NULL,
    enhanced_img_id UUID REFERENCES image_assets(image_asset_id) ON DELETE SET NULL,
    prompt_id UUID,
    operation_type VARCHAR(255),  -- 'translate', 'ad_copy_gen', 'eng_to_kor', 'feed_gen'
    request JSONB,  -- ìš”ì²­ ë°ì´í„°
    response JSONB,  -- ì‘ë‹µ ë°ì´í„°
    latency_ms FLOAT,  -- ì§€ì—° ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    -- í† í° ì‚¬ìš©ëŸ‰ ì •ë³´
    prompt_tokens INTEGER,  -- í”„ë¡¬í”„íŠ¸ í† í° ìˆ˜
    completion_tokens INTEGER,  -- ìƒì„± í† í° ìˆ˜
    total_tokens INTEGER,  -- ì´ í† í° ìˆ˜
    token_usage JSONB,  -- í† í° ì‚¬ìš©ëŸ‰ ì›ë³¸
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_llm_traces_job_id ON llm_traces(job_id);
CREATE INDEX idx_llm_traces_operation_type ON llm_traces(operation_type);
CREATE INDEX idx_llm_traces_llm_model_id ON llm_traces(llm_model_id);
CREATE INDEX idx_llm_traces_created_at ON llm_traces(created_at);
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ì™„ì „í•œ ì¶”ì **: ìš”ì²­/ì‘ë‹µ ëª¨ë‘ JSONBë¡œ ì €ì¥
- **í† í° ì •ë³´**: ì„¸ ê°€ì§€ í† í° ì •ë³´ + ì›ë³¸ JSON
- **ì¸ë±ìŠ¤**: ë¹ ë¥¸ ì¡°íšŒë¥¼ ìœ„í•œ ì¸ë±ìŠ¤
- **ì™¸ë˜ í‚¤**: ê´€ë ¨ í…Œì´ë¸”ê³¼ ì—°ê²°

---

### 2. LLM Trace ì €ì¥ ì˜ˆì‹œ

**íŒŒì¼**: `services/gpt_service.py`

```python
def translate_eng_to_kor(
    text: str,
    llm_model_id: Optional[str],
    job_id: str,
    tenant_id: str
) -> Dict[str, Any]:
    """ì˜ì–´ â†’ í•œê¸€ ë³€í™˜ (LLM Trace í¬í•¨)"""
    from openai import OpenAI
    from database import SessionLocal
    from sqlalchemy import text
    import time
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    # 1. ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    
    # 2. GPT API í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a translator..."},
            {"role": "user", "content": f"Translate: {text}"}
        ],
        temperature=0.7
    )
    
    # 3. ì§€ì—° ì‹œê°„ ê³„ì‚°
    latency_ms = (time.time() - start_time) * 1000
    
    # 4. í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
    usage = response.usage
    prompt_tokens = usage.prompt_tokens if usage else None
    completion_tokens = usage.completion_tokens if usage else None
    total_tokens = usage.total_tokens if usage else None
    
    # 5. LLM Trace ì €ì¥
    db = SessionLocal()
    try:
        llm_trace_id = uuid.uuid4()
        db.execute(text("""
            INSERT INTO llm_traces (
                llm_trace_id, job_id, llm_model_id,
                provider, operation_type,
                request, response,
                prompt_tokens, completion_tokens, total_tokens,
                token_usage, latency_ms,
                created_at, updated_at
            ) VALUES (
                :llm_trace_id, :job_id, :llm_model_id,
                'gpt', 'eng_to_kor',
                CAST(:request AS jsonb), CAST(:response AS jsonb),
                :prompt_tokens, :completion_tokens, :total_tokens,
                CAST(:token_usage AS jsonb), :latency_ms,
                CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
            )
        """), {
            "llm_trace_id": llm_trace_id,
            "job_id": uuid.UUID(job_id),
            "llm_model_id": uuid.UUID(llm_model_id) if llm_model_id else None,
            "request": json.dumps({"text": text}),
            "response": json.dumps({
                "translated_text": response.choices[0].message.content
            }),
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "token_usage": json.dumps({
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            }) if usage else None,
            "latency_ms": latency_ms
        })
        db.commit()
    finally:
        db.close()
    
    return {
        "translated_text": response.choices[0].message.content,
        "llm_trace_id": str(llm_trace_id)
    }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ì‹œì‘ ì‹œê°„ ê¸°ë¡**: ì •í™•í•œ ì§€ì—° ì‹œê°„ ì¸¡ì •
- **í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ**: API ì‘ë‹µì—ì„œ ìë™ ì¶”ì¶œ
- **ì™„ì „í•œ ì €ì¥**: ìš”ì²­/ì‘ë‹µ ëª¨ë‘ JSONBë¡œ ì €ì¥
- **ì—ëŸ¬ ì²˜ë¦¬**: try-finallyë¡œ ì•ˆì „í•œ ì²˜ë¦¬

---

### 3. Job ë° Variant ìƒíƒœ ê´€ë¦¬

**íŒŒì¼**: `database.py`

```python
class Job(Base):
    """Jobs ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸"""
    __tablename__ = "jobs"
    
    job_id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    tenant_id = Column(String(255), nullable=False)
    store_id = Column(UUID(as_uuid=True), ForeignKey("stores.store_id"), nullable=True)
    status = Column(String(50), nullable=False)  # 'queued', 'running', 'done', 'failed'
    current_step = Column(String(255), nullable=True)  # 'img_gen', 'vlm_analyze', ...
    retry_count = Column(Integer, default=0)  # ì¬ì‹œë„ íšŸìˆ˜
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())

class JobVariant(Base):
    """Job Variants ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸"""
    __tablename__ = "jobs_variants"
    
    job_variants_id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    job_id = Column(UUID(as_uuid=True), ForeignKey("jobs.job_id"), nullable=False)
    img_asset_id = Column(UUID(as_uuid=True), ForeignKey("image_assets.image_asset_id"), nullable=True)
    creation_order = Column(Integer, nullable=False)
    status = Column(String(50), nullable=False)  # 'queued', 'running', 'done', 'failed'
    current_step = Column(String(255), nullable=True)  # 'img_gen', 'vlm_analyze', ...
    retry_count = Column(Integer, default=0)  # ì¬ì‹œë„ íšŸìˆ˜
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ìƒíƒœ ê´€ë¦¬**: queued, running, done, failed ìƒíƒœ ì¶”ì 
- **ë‹¨ê³„ ì¶”ì **: current_stepìœ¼ë¡œ í˜„ì¬ ë‹¨ê³„ ì¶”ì 
- **ì¬ì‹œë„ ì¶”ì **: retry_countë¡œ ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì 
- **íƒ€ì„ìŠ¤íƒ¬í”„**: created_at, updated_atìœ¼ë¡œ ì‹œê°„ ì¶”ì 

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ì¿¼ë¦¬

### 1. ë¹„ìš© ëª¨ë‹ˆí„°ë§

```sql
-- ì‘ì—… ìœ í˜•ë³„ í† í° ì‚¬ìš©ëŸ‰ ì§‘ê³„
SELECT 
    operation_type,
    COUNT(*) as call_count,
    SUM(prompt_tokens) as total_prompt_tokens,
    SUM(completion_tokens) as total_completion_tokens,
    SUM(total_tokens) as total_tokens,
    AVG(latency_ms) as avg_latency_ms
FROM llm_traces
WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY operation_type
ORDER BY total_tokens DESC;
```

---

### 2. ì„±ëŠ¥ ë¶„ì„

```sql
-- ì‘ì—… ìœ í˜•ë³„ í‰ê·  ì§€ì—° ì‹œê°„
SELECT 
    operation_type,
    COUNT(*) as call_count,
    AVG(latency_ms) as avg_latency_ms,
    MIN(latency_ms) as min_latency_ms,
    MAX(latency_ms) as max_latency_ms,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY latency_ms) as median_latency_ms
FROM llm_traces
WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY operation_type
ORDER BY avg_latency_ms DESC;
```

---

### 3. Job ì§„í–‰ ìƒí™© ì¶”ì 

```sql
-- Jobë³„ ì§„í–‰ ìƒí™©
SELECT 
    j.job_id,
    j.status,
    j.current_step,
    j.retry_count,
    COUNT(DISTINCT jv.job_variants_id) as total_variants,
    COUNT(DISTINCT CASE WHEN jv.status = 'done' THEN jv.job_variants_id END) as completed_variants,
    COUNT(DISTINCT CASE WHEN jv.status = 'failed' THEN jv.job_variants_id END) as failed_variants
FROM jobs j
LEFT JOIN jobs_variants jv ON j.job_id = jv.job_id
WHERE j.created_at >= CURRENT_DATE - INTERVAL '1 day'
GROUP BY j.job_id, j.status, j.current_step, j.retry_count
ORDER BY j.created_at DESC;
```

---

### 4. Variantë³„ ì§„í–‰ ìƒí™©

```sql
-- Variantë³„ ì§„í–‰ ìƒí™©
SELECT 
    jv.job_variants_id,
    jv.job_id,
    jv.status,
    jv.current_step,
    jv.retry_count,
    jv.created_at,
    jv.updated_at,
    EXTRACT(EPOCH FROM (jv.updated_at - jv.created_at)) as duration_seconds
FROM jobs_variants jv
WHERE jv.job_id = 'your-job-id'
ORDER BY jv.creation_order;
```

---

### 5. ì‹¤íŒ¨ ë¶„ì„

```sql
-- ì‹¤íŒ¨í•œ Job ë¶„ì„
SELECT 
    j.job_id,
    j.status,
    j.current_step,
    j.retry_count,
    COUNT(DISTINCT jv.job_variants_id) as failed_variants,
    MAX(jv.updated_at) as last_updated
FROM jobs j
INNER JOIN jobs_variants jv ON j.job_id = jv.job_id
WHERE j.status = 'failed' OR jv.status = 'failed'
  AND j.created_at >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY j.job_id, j.status, j.current_step, j.retry_count
ORDER BY last_updated DESC;
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: í† í° ì‚¬ìš©ëŸ‰ì´ null

**ì¦ìƒ**: `llm_traces` í…Œì´ë¸”ì˜ í† í° ê´€ë ¨ ì»¬ëŸ¼ì´ null

**ì›ì¸**: OpenAI API ì‘ë‹µì— `usage` ì •ë³´ê°€ ì—†ìŒ

**í•´ê²° ë°©ë²•**:
```python
# usage ì •ë³´ í™•ì¸ ë° ë¡œê¹…
if response.usage:
    prompt_tokens = response.usage.prompt_tokens
    completion_tokens = response.usage.completion_tokens
    total_tokens = response.usage.total_tokens
else:
    logger.warning(f"OpenAI API ì‘ë‹µì— usage ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤: {response}")
    # ê¸°ë³¸ê°’ ì„¤ì • ë˜ëŠ” ì¬ì‹œë„
```

---

### ë¬¸ì œ 2: Jobì´ ë©ˆì¶¤

**ì¦ìƒ**: Jobì´ 'running' ìƒíƒœì—ì„œ ë©ˆì¶¤

**í™•ì¸ ë°©ë²•**:
```sql
-- ë©ˆì¶˜ Job í™•ì¸
SELECT 
    j.job_id,
    j.status,
    j.current_step,
    j.updated_at,
    EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - j.updated_at)) as seconds_since_update
FROM jobs j
WHERE j.status = 'running'
  AND j.updated_at < CURRENT_TIMESTAMP - INTERVAL '1 hour'
ORDER BY j.updated_at ASC;
```

**í•´ê²° ë°©ë²•**:
1. ìˆ˜ë™ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
2. ìë™ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ í™•ì¸
3. ë¡œê·¸ í™•ì¸

---

### ë¬¸ì œ 3: Variantê°€ ë’¤ì²˜ì§

**ì¦ìƒ**: ì¼ë¶€ Variantsë§Œ ì§„í–‰ë˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë©ˆì¶¤

**í™•ì¸ ë°©ë²•**:
```sql
-- ë’¤ì²˜ì§„ Variants í™•ì¸
SELECT 
    jv.job_variants_id,
    jv.job_id,
    jv.status,
    jv.current_step,
    jv.updated_at,
    j.current_step as job_current_step
FROM jobs_variants jv
INNER JOIN jobs j ON jv.job_id = j.job_id
WHERE j.status = 'running'
  AND jv.status != 'done'
  AND jv.current_step != j.current_step
ORDER BY jv.updated_at ASC;
```

**í•´ê²° ë°©ë²•**:
- ìë™ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ì´ ì‘ë™í•©ë‹ˆë‹¤
- Job ìƒíƒœê°€ ë³€ê²½ë˜ë©´ ìë™ìœ¼ë¡œ ë’¤ì²˜ì§„ Variants ë³µêµ¬

---

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ë¹„ìš© ë¶„ì„

```python
from database import SessionLocal
from sqlalchemy import text

db = SessionLocal()
try:
    # ì‘ì—… ìœ í˜•ë³„ í† í° ì‚¬ìš©ëŸ‰ ì§‘ê³„
    result = db.execute(text("""
        SELECT 
            operation_type,
            COUNT(*) as call_count,
            SUM(total_tokens) as total_tokens,
            AVG(latency_ms) as avg_latency_ms
        FROM llm_traces
        WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'
        GROUP BY operation_type
        ORDER BY total_tokens DESC
    """))
    
    for row in result:
        print(f"{row.operation_type}: {row.total_tokens} tokens, {row.avg_latency_ms:.2f}ms")
finally:
    db.close()
```

---

### ì˜ˆì‹œ 2: Job ì§„í–‰ ìƒí™© í™•ì¸

```python
from database import SessionLocal
from sqlalchemy import text

db = SessionLocal()
try:
    # Job ì§„í–‰ ìƒí™© í™•ì¸
    result = db.execute(text("""
        SELECT 
            j.job_id,
            j.status,
            j.current_step,
            COUNT(DISTINCT jv.job_variants_id) as total_variants,
            COUNT(DISTINCT CASE WHEN jv.status = 'done' THEN jv.job_variants_id END) as completed_variants
        FROM jobs j
        LEFT JOIN jobs_variants jv ON j.job_id = jv.job_id
        WHERE j.job_id = :job_id
        GROUP BY j.job_id, j.status, j.current_step
    """), {"job_id": job_id})
    
    row = result.first()
    if row:
        print(f"Job: {row.status}, Step: {row.current_step}")
        print(f"Variants: {row.completed_variants}/{row.total_variants} completed")
finally:
    db.close()
```

---

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

1. **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  LLM í˜¸ì¶œê³¼ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì¶”ì 
2. **ë¹„ìš© ëª¨ë‹ˆí„°ë§**: í† í° ì‚¬ìš©ëŸ‰ìœ¼ë¡œ ë¹„ìš© ê´€ë¦¬
3. **ì„±ëŠ¥ ë¶„ì„**: ì§€ì—° ì‹œê°„ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
4. **ì¥ì•  ë³µêµ¬**: ìƒíƒœ ê´€ë¦¬ë¡œ ìë™ ë³µêµ¬ ì§€ì›

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- `DOCS_JS_PART_IMPLEMENTATION.md`: LLM ì¶”ì  êµ¬í˜„ ìƒì„¸
- `DOCS_JOB_STATE_LISTENER.md`: Job ìƒíƒœ ê´€ë¦¬ ìƒì„¸

---

**ì‘ì„±ì¼**: 2025-12-02  
**ì‘ì„±ì**: LEEYH205  
**ë²„ì „**: 1.0.0

