# í…ìŠ¤íŠ¸ ìƒì„± ë° ë³€í™˜ ë°œí‘œìë£Œ

## ğŸ“‹ ê°œìš”

**ê¸°ëŠ¥ëª…**: GPT ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„± ë° ë³€í™˜ ì‹œìŠ¤í…œ

**ëª©ì **: ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ê´‘ê³ ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ê³ , ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ë³€í™˜í•˜ì—¬ ìµœì¢… ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ì„ ìƒì„±

**í•µì‹¬ ê°€ì¹˜**: 
- ìì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤íŠ¸ ìƒì„±
- ì •í™•í•œ ë²ˆì—­
- SNS ìµœì í™” ì½˜í…ì¸ 
- ì™„ì „í•œ LLM í˜¸ì¶œ ì¶”ì 

---

## ğŸ¯ ëª©ì 

### ë¬¸ì œ í•´ê²°
- **ìˆ˜ë™ ì‘ì—…ì˜ í•œê³„**: ê´‘ê³ ë¬¸êµ¬ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•¨
- **ë²ˆì—­ í’ˆì§ˆ**: ê¸°ê³„ ë²ˆì—­ì˜ ë¶€ìì—°ìŠ¤ëŸ¬ì›€
- **SNS ìµœì í™”**: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜ í•„ìš”

### í•´ê²° ë°©ì•ˆ
- GPT APIë¥¼ í™œìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤íŠ¸ ìƒì„±
- ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ì •í™•í•œ ë²ˆì—­
- ì¸ìŠ¤íƒ€ê·¸ë¨ ìµœì í™” í˜•ì‹ìœ¼ë¡œ ìë™ ë³€í™˜
- ëª¨ë“  LLM í˜¸ì¶œ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§

---

## âœ¨ ì£¼ìš” íŠ¹ì§•

### 1. ë‹¤êµ­ì–´ ì§€ì›
- **í•œêµ­ì–´ â†’ ì˜ì–´**: ì‚¬ìš©ì ì…ë ¥ í•œêµ­ì–´ ì„¤ëª…ì„ ì˜ì–´ë¡œ ë³€í™˜
- **ì˜ì–´ â†’ í•œê¸€**: ìµœì¢… ê´‘ê³ ë¬¸êµ¬ë¥¼ í•œê¸€ë¡œ ë³€í™˜
- **ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­**: ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­

### 2. ê´‘ê³ ë¬¸êµ¬ ìƒì„±
- **í†¤&ìŠ¤íƒ€ì¼ ë°˜ì˜**: ì‚¬ìš©ìê°€ ì„ íƒí•œ í†¤&ìŠ¤íƒ€ì¼ì— ë§ì¶° ìƒì„±
- **ì œí’ˆ ì„¤ëª… ê¸°ë°˜**: ì œí’ˆ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ê´‘ê³ ë¬¸êµ¬ ìƒì„±
- **ìŠ¤í† ì–´ ì •ë³´ í†µí•©**: ìŠ¤í† ì–´ ì •ë³´ë¥¼ í¬í•¨í•œ ë§ì¶¤í˜• ê´‘ê³ ë¬¸êµ¬

### 3. ì¸ìŠ¤íƒ€ê·¸ë¨ ìµœì í™”
- **í•´ì‹œíƒœê·¸ ìë™ ìƒì„±**: ê´€ë ¨ í•´ì‹œíƒœê·¸ ìë™ ì¶”ì¶œ
- **SNS í˜•ì‹ ìµœì í™”**: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
- **ìŠ¤í† ì–´ ì •ë³´ í†µí•©**: ìŠ¤í† ì–´ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨

### 4. ì™„ì „í•œ ì¶”ì 
- **ëª¨ë“  í˜¸ì¶œ ì¶”ì **: ëª¨ë“  LLM API í˜¸ì¶œì„ `llm_traces`ì— ì €ì¥
- **í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§**: ë¹„ìš© ê´€ë¦¬ ë° ìµœì í™”
- **ì„±ëŠ¥ ë¶„ì„**: ì§€ì—° ì‹œê°„ ë° í’ˆì§ˆ ë¶„ì„

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸

```
[ì‚¬ìš©ì ì…ë ¥]
í•œêµ­ì–´ ì„¤ëª… + í†¤&ìŠ¤íƒ€ì¼
  â†“
[í•œêµ­ì–´ â†’ ì˜ì–´ ë³€í™˜]
GPT API í˜¸ì¶œ (kor_to_eng)
  â†“
[ê´‘ê³ ë¬¸êµ¬ ìƒì„±]
GPT API í˜¸ì¶œ (ad_copy_eng)
  â†“
[ì˜ì–´ â†’ í•œê¸€ ë³€í™˜]
GPT API í˜¸ì¶œ (eng_to_kor)
  â†“
[ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±]
GPT API í˜¸ì¶œ (feed_gen)
  â†“
[ìµœì¢… ê²°ê³¼]
ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ + í•´ì‹œíƒœê·¸
```

---

## ğŸ’» êµ¬í˜„ ì½”ë“œ

### 1. ì˜ì–´ â†’ í•œê¸€ ë³€í™˜

**íŒŒì¼**: `routers/gpt.py`

```python
@router.post("/eng-to-kor", response_model=EngToKorOut)
def eng_to_kor(body: EngToKorIn, db: Session = Depends(get_db)):
    """
    ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ë¥¼ í•œê¸€ë¡œ ë³€í™˜
    
    Args:
        body: EngToKorIn ëª¨ë¸
            - job_id: Job ID
            - tenant_id: Tenant ID
    
    Returns:
        EngToKorOut:
            - job_id: Job ID
            - llm_trace_id: LLM Trace ID
            - ad_copy_gen_id: Ad Copy Generation ID
            - ad_copy_kor: í•œê¸€ ê´‘ê³ ë¬¸êµ¬
            - status: ìƒíƒœ ('done' ë˜ëŠ” 'failed')
    """
    # 1. Job ì¡°íšŒ ë° ê²€ì¦
    job = db.query(Job).filter(Job.job_id == body.job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail=f"Job not found: {body.job_id}")
    
    # 2. ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ ì¡°íšŒ (refined_ad_copy_eng ìš°ì„ )
    ad_copy_gen = db.execute(
        text("""
            SELECT 
                ad_copy_gen_id,
                COALESCE(refined_ad_copy_eng, ad_copy_eng) AS ad_copy_eng
            FROM txt_ad_copy_generations
            WHERE job_id = :job_id
              AND (
                  (generation_stage = 'refined_ad_copy' AND refined_ad_copy_eng IS NOT NULL)
                  OR (generation_stage = 'ad_copy_eng' AND ad_copy_eng IS NOT NULL)
              )
              AND status = 'done'
            ORDER BY 
                CASE generation_stage
                    WHEN 'refined_ad_copy' THEN 1
                    WHEN 'ad_copy_eng' THEN 2
                END,
                created_at DESC
            LIMIT 1
        """),
        {"job_id": job.job_id}
    ).first()
    
    if not ad_copy_gen or not ad_copy_gen.ad_copy_eng:
        raise HTTPException(
            status_code=400,
            detail=f"English ad copy not found for job_id: {body.job_id}"
        )
    
    # 3. LLM ëª¨ë¸ ì¡°íšŒ
    llm_model = db.query(LLMModel).filter(
        LLMModel.model_name == GPT_MODEL_NAME
    ).first()
    llm_model_id = llm_model.llm_model_id if llm_model else None
    
    # 4. Job ìƒíƒœ ì—…ë°ì´íŠ¸ (running)
    job.status = 'running'
    job.current_step = 'ad_copy_gen_kor'
    db.commit()
    
    # 5. GPT API í˜¸ì¶œ
    try:
        result = translate_eng_to_kor(
            text=ad_copy_gen.ad_copy_eng,
            llm_model_id=str(llm_model_id) if llm_model_id else None,
            job_id=str(job.job_id),
            tenant_id=body.tenant_id
        )
        
        ad_copy_kor = result["translated_text"]
        llm_trace_id = result["llm_trace_id"]
        
        # 6. txt_ad_copy_generations ì—…ë°ì´íŠ¸
        db.execute(
            text("""
                UPDATE txt_ad_copy_generations
                SET ad_copy_kor = :ad_copy_kor,
                    status = 'done',
                    updated_at = CURRENT_TIMESTAMP
                WHERE ad_copy_gen_id = :ad_copy_gen_id
            """),
            {
                "ad_copy_kor": ad_copy_kor,
                "ad_copy_gen_id": ad_copy_gen.ad_copy_gen_id
            }
        )
        
        # 7. Job ìƒíƒœ ì—…ë°ì´íŠ¸ (done) - íŠ¸ë¦¬ê±° ìë™ ë°œë™
        job.status = 'done'
        job.current_step = 'ad_copy_gen_kor'
        db.commit()
        
        return EngToKorOut(
            job_id=str(job.job_id),
            llm_trace_id=llm_trace_id,
            ad_copy_gen_id=str(ad_copy_gen.ad_copy_gen_id),
            ad_copy_kor=ad_copy_kor,
            status="done"
        )
        
    except Exception as e:
        logger.error(f"GPT API í˜¸ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
        job.status = 'failed'
        db.commit()
        raise HTTPException(status_code=500, detail=f"Translation failed: {str(e)}")
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ìš°ì„ ìˆœìœ„ ì²˜ë¦¬**: `refined_ad_copy_eng` ìš°ì„ , ì—†ìœ¼ë©´ `ad_copy_eng` ì‚¬ìš©
- **ìƒíƒœ ê´€ë¦¬**: running â†’ doneìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ íŠ¸ë¦¬ê±° ë°œë™
- **ì—ëŸ¬ ì²˜ë¦¬**: ì‹¤íŒ¨ ì‹œ ìƒíƒœë¥¼ 'failed'ë¡œ ì—…ë°ì´íŠ¸
- **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  í˜¸ì¶œì„ `llm_traces`ì— ì €ì¥

---

### 2. GPT ì„œë¹„ìŠ¤ (ì˜ì–´ â†’ í•œê¸€ ë³€í™˜)

**íŒŒì¼**: `services/gpt_service.py`

```python
def translate_eng_to_kor(
    text: str,
    llm_model_id: Optional[str],
    job_id: str,
    tenant_id: str
) -> Dict[str, Any]:
    """ì˜ì–´ â†’ í•œê¸€ ë³€í™˜"""
    from openai import OpenAI
    from database import SessionLocal
    from sqlalchemy import text
    import time
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    # 1. ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    
    # 2. GPT API í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "You are a professional translator. Translate the given English text to Korean naturally and fluently, maintaining the original tone and style."
            },
            {
                "role": "user",
                "content": f"Translate the following English text to Korean:\n\n{text}"
            }
        ],
        temperature=0.7,
        max_tokens=1000
    )
    
    # 3. ì§€ì—° ì‹œê°„ ê³„ì‚°
    latency_ms = (time.time() - start_time) * 1000
    
    # 4. í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
    usage = response.usage
    prompt_tokens = usage.prompt_tokens if usage else None
    completion_tokens = usage.completion_tokens if usage else None
    total_tokens = usage.total_tokens if usage else None
    
    # 5. LLM Trace ì €ì¥
    db = SessionLocal()
    try:
        llm_trace_id = uuid.uuid4()
        db.execute(text("""
            INSERT INTO llm_traces (
                llm_trace_id, job_id, llm_model_id,
                provider, operation_type,
                request, response,
                prompt_tokens, completion_tokens, total_tokens,
                token_usage, latency_ms,
                created_at, updated_at
            ) VALUES (
                :llm_trace_id, :job_id, :llm_model_id,
                'gpt', 'eng_to_kor',
                CAST(:request AS jsonb), CAST(:response AS jsonb),
                :prompt_tokens, :completion_tokens, :total_tokens,
                CAST(:token_usage AS jsonb), :latency_ms,
                CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
            )
        """), {
            "llm_trace_id": llm_trace_id,
            "job_id": uuid.UUID(job_id),
            "llm_model_id": uuid.UUID(llm_model_id) if llm_model_id else None,
            "request": json.dumps({"text": text}),
            "response": json.dumps({
                "translated_text": response.choices[0].message.content
            }),
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "token_usage": json.dumps({
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            }) if usage else None,
            "latency_ms": latency_ms
        })
        db.commit()
    finally:
        db.close()
    
    return {
        "translated_text": response.choices[0].message.content,
        "llm_trace_id": str(llm_trace_id)
    }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ**: API ì‘ë‹µì—ì„œ ìë™ ì¶”ì¶œ
- **ì§€ì—° ì‹œê°„ ì¸¡ì •**: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- **ì™„ì „í•œ ì¶”ì **: ìš”ì²­/ì‘ë‹µ ëª¨ë‘ ì €ì¥
- **ì—ëŸ¬ ì²˜ë¦¬**: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì ì ˆí•œ ì²˜ë¦¬

---

### 3. ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±

**íŒŒì¼**: `routers/instagram_feed.py`

```python
@router.post("/feed", response_model=InstagramFeedOut)
def create_instagram_feed(body: InstagramFeedIn, db: Session = Depends(get_db)):
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ ìƒì„± ë° DB ì €ì¥
    
    ì²˜ë¦¬ ê³¼ì •:
    1. txt_ad_copy_generationsì—ì„œ í•œê¸€ ê´‘ê³ ë¬¸êµ¬ ì¡°íšŒ
    2. job_inputsì—ì„œ tone_style, product_description ì¡°íšŒ
    3. stores í…Œì´ë¸”ì—ì„œ ìŠ¤í† ì–´ ì •ë³´ ì¡°íšŒ
    4. GPT API í˜¸ì¶œí•˜ì—¬ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œê¸€ ìƒì„±
    5. llm_traces ì €ì¥
    6. instagram_feeds ì €ì¥
    7. jobs í…Œì´ë¸” ì—…ë°ì´íŠ¸
    """
    # 1. Job ì¡°íšŒ ë° ê²€ì¦
    job = db.query(Job).filter(Job.job_id == body.job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail=f"Job not found: {body.job_id}")
    
    # 2. í•œê¸€ ê´‘ê³ ë¬¸êµ¬ ì¡°íšŒ
    ad_copy_kor_row = db.execute(
        text("""
            SELECT ad_copy_kor
            FROM txt_ad_copy_generations
            WHERE job_id = :job_id
              AND generation_stage = 'eng_to_kor'
              AND status = 'done'
            ORDER BY created_at DESC
            LIMIT 1
        """),
        {"job_id": job.job_id}
    ).first()
    
    ad_copy_kor = ad_copy_kor_row.ad_copy_kor if ad_copy_kor_row else None
    
    # 3. ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ ì¡°íšŒ (refined_ad_copy_eng ìš°ì„ )
    refined_ad_copy_row = db.execute(
        text("""
            SELECT COALESCE(refined_ad_copy_eng, ad_copy_eng) AS refined_ad_copy_eng
            FROM txt_ad_copy_generations
            WHERE job_id = :job_id
              AND (
                  (generation_stage = 'refined_ad_copy' AND refined_ad_copy_eng IS NOT NULL)
                  OR (generation_stage = 'ad_copy_eng' AND ad_copy_eng IS NOT NULL)
              )
              AND status = 'done'
            ORDER BY 
                CASE generation_stage
                    WHEN 'refined_ad_copy' THEN 1
                    WHEN 'ad_copy_eng' THEN 2
                END,
                created_at DESC
            LIMIT 1
        """),
        {"job_id": job.job_id}
    ).first()
    
    refined_ad_copy_eng = refined_ad_copy_row.refined_ad_copy_eng if refined_ad_copy_row else None
    
    # 4. Job Inputs ì¡°íšŒ
    job_input = db.query(JobInput).filter(JobInput.job_id == job.job_id).first()
    product_description = job_input.desc_kor if job_input else ""
    tone_style_name = job_input.tone_style.tone_style_name if job_input and job_input.tone_style else ""
    
    # 5. Store ì •ë³´ ì¡°íšŒ
    store = db.query(Store).filter(Store.store_id == job.store_id).first()
    store_info = {
        "store_name": store.store_name if store else "",
        "store_address": store.store_address if store else "",
        "store_phone": store.store_phone if store else ""
    }
    
    # 6. Job ìƒíƒœ ì—…ë°ì´íŠ¸ (running)
    job.status = 'running'
    job.current_step = 'instagram_feed_gen'
    db.commit()
    
    # 7. GPT API í˜¸ì¶œ
    try:
        result = generate_instagram_feed(
            ad_copy_kor=ad_copy_kor,
            refined_ad_copy_eng=refined_ad_copy_eng,
            product_description=product_description,
            tone_style_name=tone_style_name,
            store_info=store_info,
            gpt_prompt=body.gpt_prompt,
            llm_model_id=str(llm_model.llm_model_id) if llm_model else None,
            job_id=str(job.job_id),
            tenant_id=body.tenant_id
        )
        
        feed_text = result["feed_text"]
        hashtags = result["hashtags"]
        llm_trace_id = result["llm_trace_id"]
        
        # 8. Instagram Feed ì €ì¥
        instagram_feed = InstagramFeed(
            instagram_feed_id=uuid.uuid4(),
            job_id=job.job_id,
            llm_trace_id=uuid.UUID(llm_trace_id),
            gpt_prompt=body.gpt_prompt,
            ad_copy_kor=ad_copy_kor,
            instagram_ad_copy=feed_text,
            hashtags=hashtags
        )
        db.add(instagram_feed)
        
        # 9. Job ìƒíƒœ ì—…ë°ì´íŠ¸ (done) - íŒŒì´í”„ë¼ì¸ ì™„ë£Œ
        job.status = 'done'
        job.current_step = 'instagram_feed_gen'
        db.commit()
        
        return InstagramFeedOut(
            instagram_feed_id=str(instagram_feed.instagram_feed_id),
            instagram_ad_copy=feed_text,
            hashtags=hashtags
        )
        
    except Exception as e:
        logger.error(f"Instagram feed generation failed: {e}", exc_info=True)
        job.status = 'failed'
        db.commit()
        raise HTTPException(status_code=500, detail=f"Feed generation failed: {str(e)}")
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ë°ì´í„° í†µí•©**: ì—¬ëŸ¬ í…Œì´ë¸”ì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¡°íšŒ
- **ìš°ì„ ìˆœìœ„ ì²˜ë¦¬**: `refined_ad_copy_eng` ìš°ì„  ì‚¬ìš©
- **SNS ìµœì í™”**: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ìƒì„±
- **í•´ì‹œíƒœê·¸ ìë™ ìƒì„±**: ê´€ë ¨ í•´ì‹œíƒœê·¸ ìë™ ì¶”ì¶œ

---

### 4. GPT ì„œë¹„ìŠ¤ (ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±)

**íŒŒì¼**: `services/gpt_service.py`

```python
def generate_instagram_feed(
    ad_copy_kor: Optional[str],
    refined_ad_copy_eng: Optional[str],
    product_description: str,
    tone_style_name: str,
    store_info: Dict[str, str],
    gpt_prompt: str,
    llm_model_id: Optional[str],
    job_id: str,
    tenant_id: str
) -> Dict[str, Any]:
    """ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ ìƒì„±"""
    from openai import OpenAI
    from database import SessionLocal
    from sqlalchemy import text
    import time
    import re
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    # 1. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = """You are a professional social media content creator. 
    Create an engaging Instagram post in Korean that includes:
    1. An attractive caption based on the ad copy
    2. Relevant hashtags (5-10 hashtags)
    3. Natural integration of store information
    
    The post should be:
    - Engaging and appealing to Instagram users
    - Natural and conversational
    - Include relevant emojis where appropriate
    - Optimized for Instagram's format"""
    
    user_prompt = f"""
    Create an Instagram post with the following information:
    
    Ad Copy (Korean): {ad_copy_kor or 'N/A'}
    Ad Copy (English): {refined_ad_copy_eng or 'N/A'}
    Product Description: {product_description}
    Tone & Style: {tone_style_name}
    Store Name: {store_info.get('store_name', 'N/A')}
    Store Address: {store_info.get('store_address', 'N/A')}
    Store Phone: {store_info.get('store_phone', 'N/A')}
    
    Additional Instructions: {gpt_prompt}
    
    Please create:
    1. The main Instagram post text (in Korean)
    2. Relevant hashtags (5-10 hashtags, separated by spaces)
    
    Format your response as:
    POST: [your post text here]
    HASHTAGS: [hashtags here, separated by spaces]
    """
    
    # 2. ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    
    # 3. GPT API í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.8,
        max_tokens=GPT_MAX_TOKENS
    )
    
    # 4. ì§€ì—° ì‹œê°„ ê³„ì‚°
    latency_ms = (time.time() - start_time) * 1000
    
    # 5. ì‘ë‹µ íŒŒì‹±
    response_text = response.choices[0].message.content
    
    # POSTì™€ HASHTAGS ì¶”ì¶œ
    post_match = re.search(r'POST:\s*(.*?)(?=HASHTAGS:|$)', response_text, re.DOTALL)
    hashtags_match = re.search(r'HASHTAGS:\s*(.*?)$', response_text, re.DOTALL)
    
    feed_text = post_match.group(1).strip() if post_match else response_text
    hashtags_text = hashtags_match.group(1).strip() if hashtags_match else ""
    
    # í•´ì‹œíƒœê·¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    hashtags = [tag.strip() for tag in hashtags_text.split() if tag.strip().startswith('#')]
    
    # 6. í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
    usage = response.usage
    prompt_tokens = usage.prompt_tokens if usage else None
    completion_tokens = usage.completion_tokens if usage else None
    total_tokens = usage.total_tokens if usage else None
    
    # 7. LLM Trace ì €ì¥
    db = SessionLocal()
    try:
        llm_trace_id = uuid.uuid4()
        db.execute(text("""
            INSERT INTO llm_traces (
                llm_trace_id, job_id, llm_model_id,
                provider, operation_type,
                request, response,
                prompt_tokens, completion_tokens, total_tokens,
                token_usage, latency_ms,
                created_at, updated_at
            ) VALUES (
                :llm_trace_id, :job_id, :llm_model_id,
                'gpt', 'feed_gen',
                CAST(:request AS jsonb), CAST(:response AS jsonb),
                :prompt_tokens, :completion_tokens, :total_tokens,
                CAST(:token_usage AS jsonb), :latency_ms,
                CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
            )
        """), {
            "llm_trace_id": llm_trace_id,
            "job_id": uuid.UUID(job_id),
            "llm_model_id": uuid.UUID(llm_model_id) if llm_model_id else None,
            "request": json.dumps({
                "ad_copy_kor": ad_copy_kor,
                "refined_ad_copy_eng": refined_ad_copy_eng,
                "product_description": product_description,
                "tone_style_name": tone_style_name,
                "store_info": store_info,
                "gpt_prompt": gpt_prompt
            }),
            "response": json.dumps({
                "feed_text": feed_text,
                "hashtags": hashtags
            }),
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "token_usage": json.dumps({
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            }) if usage else None,
            "latency_ms": latency_ms
        })
        db.commit()
    finally:
        db.close()
    
    return {
        "feed_text": feed_text,
        "hashtags": hashtags,
        "llm_trace_id": str(llm_trace_id)
    }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
- **ì‘ë‹µ íŒŒì‹±**: POSTì™€ HASHTAGSë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¦¬
- **í•´ì‹œíƒœê·¸ ì¶”ì¶œ**: ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í•´ì‹œíƒœê·¸ ìë™ ì¶”ì¶œ
- **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  í˜¸ì¶œì„ `llm_traces`ì— ì €ì¥

---

## ğŸ“Š ì‘ì—… ìœ í˜•ë³„ ìƒì„¸

### 1. kor_to_eng (í•œêµ­ì–´ â†’ ì˜ì–´)
- **ëª©ì **: ì‚¬ìš©ì ì…ë ¥ í•œêµ­ì–´ ì„¤ëª…ì„ ì˜ì–´ë¡œ ë³€í™˜
- **ì…ë ¥**: `job_inputs.desc_kor`
- **ì¶œë ¥**: `txt_ad_copy_generations.ad_copy_eng`
- **ì‚¬ìš© ì‹œì **: íŒŒì´í”„ë¼ì¸ ì´ˆê¸° ë‹¨ê³„

### 2. ad_copy_eng (ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ ìƒì„±)
- **ëª©ì **: ì œí’ˆ ì„¤ëª… ê¸°ë°˜ ì˜ì–´ ê´‘ê³ ë¬¸êµ¬ ìƒì„±
- **ì…ë ¥**: ì˜ì–´ ì œí’ˆ ì„¤ëª…, í†¤&ìŠ¤íƒ€ì¼
- **ì¶œë ¥**: `txt_ad_copy_generations.ad_copy_eng`
- **ì‚¬ìš© ì‹œì **: JS íŒŒíŠ¸ì—ì„œ ì²˜ë¦¬

### 3. eng_to_kor (ì˜ì–´ â†’ í•œê¸€)
- **ëª©ì **: ìµœì¢… ê´‘ê³ ë¬¸êµ¬ë¥¼ í•œê¸€ë¡œ ë³€í™˜
- **ì…ë ¥**: `txt_ad_copy_generations.refined_ad_copy_eng` ë˜ëŠ” `ad_copy_eng`
- **ì¶œë ¥**: `txt_ad_copy_generations.ad_copy_kor`
- **ì‚¬ìš© ì‹œì **: íŒŒì´í”„ë¼ì¸ í›„ë°˜ë¶€ (ëª¨ë“  variants ì™„ë£Œ í›„)

### 4. feed_gen (ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±)
- **ëª©ì **: ê´‘ê³ ë¬¸êµ¬, ìŠ¤í† ì–´ ì •ë³´ ê¸°ë°˜ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ ìƒì„±
- **ì…ë ¥**: í•œê¸€ ê´‘ê³ ë¬¸êµ¬, ì˜ì–´ ê´‘ê³ ë¬¸êµ¬, ì œí’ˆ ì„¤ëª…, ìŠ¤í† ì–´ ì •ë³´
- **ì¶œë ¥**: `instagram_feeds.instagram_ad_copy`, `hashtags`
- **ì‚¬ìš© ì‹œì **: íŒŒì´í”„ë¼ì¸ ìµœì¢… ë‹¨ê³„

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: í† í° ì‚¬ìš©ëŸ‰ì´ null

**ì¦ìƒ**: `llm_traces` í…Œì´ë¸”ì˜ í† í° ê´€ë ¨ ì»¬ëŸ¼ì´ null

**ì›ì¸**: OpenAI API ì‘ë‹µì— `usage` ì •ë³´ê°€ ì—†ìŒ

**í•´ê²° ë°©ë²•**:
```python
# usage ì •ë³´ í™•ì¸
if response.usage:
    prompt_tokens = response.usage.prompt_tokens
    completion_tokens = response.usage.completion_tokens
    total_tokens = response.usage.total_tokens
else:
    logger.warning("OpenAI API ì‘ë‹µì— usage ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
```

---

### ë¬¸ì œ 2: ë²ˆì—­ í’ˆì§ˆì´ ë‚®ìŒ

**ì¦ìƒ**: ë²ˆì—­ëœ í…ìŠ¤íŠ¸ê°€ ë¶€ìì—°ìŠ¤ëŸ¬ì›€

**í•´ê²° ë°©ë²•**:
1. í”„ë¡¬í”„íŠ¸ ê°œì„ 
   ```python
   system_prompt = """You are a professional translator. 
   Translate the given English text to Korean naturally and fluently, 
   maintaining the original tone and style. 
   Consider the context and cultural nuances."""
   ```
2. Temperature ì¡°ì •
   ```python
   temperature = 0.7  # ê¸°ë³¸ê°’, ë” ì°½ì˜ì ì´ë ¤ë©´ 0.8-0.9
   ```
3. ëª¨ë¸ ë³€ê²½
   ```python
   model = "gpt-4o"  # ë” ì •í™•í•œ ëª¨ë¸ ì‚¬ìš©
   ```

---

### ë¬¸ì œ 3: í•´ì‹œíƒœê·¸ê°€ ì¶”ì¶œë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**: `hashtags` í•„ë“œê°€ ë¹„ì–´ìˆìŒ

**ì›ì¸**: GPT ì‘ë‹µ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„

**í•´ê²° ë°©ë²•**:
1. ì‘ë‹µ í˜•ì‹ ëª…í™•í™”
   ```python
   user_prompt = """
   Format your response as:
   POST: [your post text here]
   HASHTAGS: [hashtags here, separated by spaces]
   """
   ```
2. ì •ê·œí‘œí˜„ì‹ ê°œì„ 
   ```python
   hashtags = re.findall(r'#\w+', response_text)
   ```

---

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì˜ì–´ â†’ í•œê¸€ ë³€í™˜

```python
# API í˜¸ì¶œ
response = requests.post(
    "http://localhost:8000/api/yh/gpt/eng-to-kor",
    json={
        "job_id": "xxx-xxx-xxx",
        "tenant_id": "test_tenant"
    }
)

# ê²°ê³¼
ad_copy_kor = response.json()["ad_copy_kor"]
llm_trace_id = response.json()["llm_trace_id"]
```

---

### ì˜ˆì‹œ 2: ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±

```python
# API í˜¸ì¶œ
response = requests.post(
    "http://localhost:8000/api/yh/instagram/feed",
    json={
        "job_id": "xxx-xxx-xxx",
        "tenant_id": "test_tenant",
        "gpt_prompt": "ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”"
    }
)

# ê²°ê³¼
feed_text = response.json()["instagram_ad_copy"]
hashtags = response.json()["hashtags"]
```

---

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

1. **ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­**: ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­
2. **SNS ìµœì í™”**: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ìë™ ë³€í™˜
3. **í•´ì‹œíƒœê·¸ ìë™ ìƒì„±**: ê´€ë ¨ í•´ì‹œíƒœê·¸ ìë™ ì¶”ì¶œ
4. **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  LLM í˜¸ì¶œ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- `DOCS_JS_PART_IMPLEMENTATION.md`: JS íŒŒíŠ¸ êµ¬í˜„ ê°€ì´ë“œ
- `DOCS_INSTAGRAM_FEED.md`: ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„± ìƒì„¸ ë¬¸ì„œ

---

**ì‘ì„±ì¼**: 2025-12-02  
**ì‘ì„±ì**: LEEYH205  
**ë²„ì „**: 1.0.0

