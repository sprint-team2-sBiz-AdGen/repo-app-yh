# AI ëª¨ë¸ í†µí•© ë°œí‘œìë£Œ

## ğŸ“‹ ê°œìš”

**ê¸°ëŠ¥ëª…**: AI ëª¨ë¸ í†µí•© (LLaVA, YOLO, GPT)

**ëª©ì **: ë‹¤ì–‘í•œ AI ëª¨ë¸ì„ í†µí•©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„, ê°ì²´ ê°ì§€, í…ìŠ¤íŠ¸ ìƒì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰

**í•µì‹¬ ê°€ì¹˜**: 
- ë©€í‹°ëª¨ë‹¬ AI í™œìš© (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)
- ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€
- ìì—°ì–´ ìƒì„± ë° ë³€í™˜
- GPU íš¨ìœ¨ì  ì‚¬ìš©

---

## ğŸ¯ ëª©ì 

### LLaVA (Large Language and Vision Assistant)
- **ëª©ì **: ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì¼ê´€ì„± ê²€ì¦ ë° í’ˆì§ˆ í‰ê°€
- **í™œìš©**: ê´‘ê³  ì´ë¯¸ì§€ì™€ ê´‘ê³ ë¬¸êµ¬ì˜ ì í•©ì„± ê²€ì¦

### YOLO (You Only Look Once)
- **ëª©ì **: ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê°€ëŠ¥ ì˜ì—­ ê°ì§€
- **í™œìš©**: í…ìŠ¤íŠ¸ ë°°ì¹˜ ìœ„ì¹˜ ìµœì í™”

### GPT (Generative Pre-trained Transformer)
- **ëª©ì **: í…ìŠ¤íŠ¸ ìƒì„± ë° ë³€í™˜
- **í™œìš©**: ê´‘ê³ ë¬¸êµ¬ ìƒì„±, ë²ˆì—­, í”¼ë“œ ê¸€ ìƒì„±

---

## 1ï¸âƒ£ LLaVA í†µí•©

### ëª©ì 
ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ê´‘ê³ ë¬¸êµ¬ì˜ ì í•©ì„±ì„ ê²€ì¦í•˜ê³ , ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€ì˜ ìµœì¢… í’ˆì§ˆì„ í‰ê°€

### ì£¼ìš” íŠ¹ì§•
- **Stage 1**: ì´ë¯¸ì§€ì™€ ê´‘ê³ ë¬¸êµ¬ ê²€ì¦ (ì´ˆê¸° ë‹¨ê³„)
- **Stage 2**: ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€ ìµœì¢… í’ˆì§ˆ í‰ê°€
- **GPU ê¸°ë°˜ ì¶”ë¡ **: CUDA ì§€ì›
- **Thread-safe ëª¨ë¸ ë¡œë”©**: í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì‚¬ìš©
- **8-bit ì–‘ìí™” ì§€ì›**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ

### êµ¬í˜„ ìœ„ì¹˜
- `services/llava_service.py`: LLaVA ëª¨ë¸ ì„œë¹„ìŠ¤
- `routers/llava_stage1.py`: Stage 1 API ì—”ë“œí¬ì¸íŠ¸
- `routers/llava_stage2.py`: Stage 2 API ì—”ë“œí¬ì¸íŠ¸

---

### êµ¬í˜„ ì½”ë“œ

#### 1. Thread-safe ëª¨ë¸ ë¡œë”©

**íŒŒì¼**: `services/llava_service.py`

```python
import threading
from transformers import LlavaProcessor, LlavaForConditionalGeneration

# ì „ì—­ ëª¨ë¸ ë³€ìˆ˜ (lazy loading)
_processor: Optional[LlavaProcessor] = None
_model: Optional[LlavaForConditionalGeneration] = None
_model_lock = threading.Lock()  # ëª¨ë¸ ë¡œë”© ë™ê¸°í™”ë¥¼ ìœ„í•œ ë½

def get_llava_model():
    """LLaVA ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ì‹±ê¸€í†¤ íŒ¨í„´, thread-safe)"""
    global _processor, _model
    
    # Double-checked locking íŒ¨í„´ìœ¼ë¡œ thread-safeí•˜ê²Œ ëª¨ë¸ ë¡œë”©
    if _model is None or _processor is None:
        with _model_lock:
            # ë‹¤ì‹œ í™•ì¸ (ë‹¤ë¥¸ ìŠ¤ë ˆë“œê°€ ì´ë¯¸ ë¡œë”©í–ˆì„ ìˆ˜ ìˆìŒ)
            if _model is None or _processor is None:
                print(f"Loading LLaVa model: {LLAVA_MODEL_NAME} on {DEVICE}")
                
                # í”„ë¡œì„¸ì„œ ë¡œë“œ
                _processor = LlavaProcessor.from_pretrained(
                    LLAVA_MODEL_NAME,
                    cache_dir=MODEL_DIR
                )
                
                # ëª¨ë¸ ë¡œë“œ (8-bit ì–‘ìí™” ì§€ì›)
                if DEVICE == "cuda" and USE_QUANTIZATION:
                    _model = LlavaForConditionalGeneration.from_pretrained(
                        LLAVA_MODEL_NAME,
                        cache_dir=MODEL_DIR,
                        load_in_8bit=True,
                        device_map="auto"
                    )
                else:
                    _model = LlavaForConditionalGeneration.from_pretrained(
                        LLAVA_MODEL_NAME,
                        cache_dir=MODEL_DIR,
                        torch_dtype=torch.float16 if DEVICE == "cuda" else torch.float32,
                        device_map="auto"
                    )
                
                logger.info(f"âœ“ LLaVA ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {LLAVA_MODEL_NAME}")
    
    return _processor, _model
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **Double-checked locking**: ì—¬ëŸ¬ ìŠ¤ë ˆë“œê°€ ë™ì‹œì— ì ‘ê·¼í•´ë„ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œ
- **8-bit ì–‘ìí™”**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•½ 50% ê°ì†Œ
- **Lazy loading**: í•„ìš”í•  ë•Œë§Œ ë¡œë“œ

---

#### 2. Stage 1: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ê²€ì¦

**íŒŒì¼**: `routers/llava_stage1.py`

```python
@router.post("", response_model=LLaVaStage1Out)
def llava_stage1_validate(body: LLaVaStage1In, db: Session = Depends(get_db)):
    """LLaVA Stage 1: ì´ë¯¸ì§€ì™€ ê´‘ê³ ë¬¸êµ¬ ê²€ì¦"""
    
    # 1. Job Variant ì¡°íšŒ
    job_variant = db.query(JobVariant).filter(
        JobVariant.job_variants_id == body.job_variants_id
    ).first()
    
    # 2. ìƒíƒœ ì—…ë°ì´íŠ¸ (running)
    job_variant.status = 'running'
    job_variant.current_step = 'vlm_analyze'
    db.commit()
    
    # 3. ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ ì¤€ë¹„
    image_url = job_variant.img_asset.image_url
    ad_copy_text = get_ad_copy_text_from_job(job_variant.job_id, db)
    
    # 4. LLaVA ëª¨ë¸ ì‹¤í–‰
    processor, model = get_llava_model()
    result = llava_service.validate_image_and_text(
        image_url=image_url,
        text=ad_copy_text,
        processor=processor,
        model=model
    )
    
    # 5. ìƒíƒœ ì—…ë°ì´íŠ¸ (done) - íŠ¸ë¦¬ê±° ìë™ ë°œë™
    job_variant.status = 'done'
    job_variant.current_step = 'vlm_analyze'
    db.commit()
    
    return result
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- ìƒíƒœ ê´€ë¦¬: running â†’ doneìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ íŠ¸ë¦¬ê±° ë°œë™
- ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ê²€ì¦: ê´‘ê³ ë¬¸êµ¬ê°€ ì´ë¯¸ì§€ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
- ìë™ íŠ¸ë¦¬ê±°: done ìƒíƒœë¡œ ì—…ë°ì´íŠ¸í•˜ë©´ ë‹¤ìŒ ë‹¨ê³„ ìë™ ì‹¤í–‰

---

#### 3. Stage 2: ìµœì¢… í’ˆì§ˆ í‰ê°€

**íŒŒì¼**: `routers/llava_stage2.py`

```python
@router.post("", response_model=LLaVaStage2Out)
def llava_stage2_judge(body: LLaVaStage2In, db: Session = Depends(get_db)):
    """LLaVA Stage 2: ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€ ìµœì¢… í’ˆì§ˆ í‰ê°€"""
    
    # 1. Overlay ì´ë¯¸ì§€ ì¡°íšŒ
    overlay = db.query(OverlayLayout).filter(
        OverlayLayout.overlay_id == body.overlay_id
    ).first()
    
    # 2. LLaVA ëª¨ë¸ ì‹¤í–‰
    processor, model = get_llava_model()
    result = llava_service.evaluate_overlay_quality(
        overlay_image_url=overlay.overlaid_image_url,
        processor=processor,
        model=model
    )
    
    # 3. ìƒíƒœ ì—…ë°ì´íŠ¸ (done) - íŠ¸ë¦¬ê±° ìë™ ë°œë™
    job_variant.status = 'done'
    job_variant.current_step = 'vlm_judge'
    db.commit()
    
    return result
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- ì˜¤ë²„ë ˆì´ í’ˆì§ˆ í‰ê°€: í…ìŠ¤íŠ¸ê°€ ì˜ ë³´ì´ëŠ”ì§€, ê°€ë…ì„±ì´ ì¢‹ì€ì§€ í‰ê°€
- ìë™ íŠ¸ë¦¬ê±°: ë‹¤ìŒ ë‹¨ê³„(ocr_eval)ë¡œ ìë™ ì§„í–‰

---

### íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

#### ë¬¸ì œ 1: ëª¨ë¸ì´ ì—¬ëŸ¬ ë²ˆ ë¡œë“œë¨

**ì¦ìƒ**: ë¡œê·¸ì— "Loading LLaVa model" ë©”ì‹œì§€ê°€ ì—¬ëŸ¬ ë²ˆ ë‚˜íƒ€ë‚¨

**ì›ì¸**: Thread-safe ë¡œë”©ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŒ

**í•´ê²° ë°©ë²•**:
1. `_model_lock`ì´ ì œëŒ€ë¡œ ì‚¬ìš©ë˜ê³  ìˆëŠ”ì§€ í™•ì¸
2. Double-checked locking íŒ¨í„´ í™•ì¸
3. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘

**í™•ì¸ ë°©ë²•**:
```bash
docker logs feedlyai-work-yh | grep -c "Loading LLaVa model"
# ì˜ˆìƒ: 1íšŒë§Œ ë‚˜íƒ€ë‚˜ì•¼ í•¨
```

---

#### ë¬¸ì œ 2: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ**: CUDA out of memory ì˜¤ë¥˜

**í•´ê²° ë°©ë²•**:
1. 8-bit ì–‘ìí™” í™œì„±í™”
   ```python
   USE_QUANTIZATION = True
   ```
2. ëª¨ë¸ í¬ê¸° í™•ì¸ ë° ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
3. ë°°ì¹˜ í¬ê¸° ê°ì†Œ

---

#### ë¬¸ì œ 3: ëª¨ë¸ ë¡œë”© ì‹œê°„ì´ ë„ˆë¬´ ê¹€

**ì¦ìƒ**: ì²« ìš”ì²­ ì‹œ ì‘ë‹µ ì‹œê°„ì´ ë§¤ìš° ê¹€ (1-2ë¶„)

**ì›ì¸**: ëª¨ë¸ì„ ì²˜ìŒ ë¡œë“œí•  ë•Œ ì‹œê°„ì´ ì†Œìš”ë¨

**í•´ê²° ë°©ë²•**:
- ì •ìƒì ì¸ ë™ì‘ì…ë‹ˆë‹¤
- ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œë˜ë¯€ë¡œ ì´í›„ ìš”ì²­ì€ ë¹ ë¦…ë‹ˆë‹¤
- ì›Œë°ì—… ìš”ì²­ì„ ë¯¸ë¦¬ ë³´ë‚´ëŠ” ê²ƒì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

---

## 2ï¸âƒ£ YOLO í†µí•©

### ëª©ì 
ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê°€ëŠ¥ ì˜ì—­ì„ ê°ì§€í•˜ì—¬ í…ìŠ¤íŠ¸ ë°°ì¹˜ ìœ„ì¹˜ë¥¼ ìµœì í™”

### ì£¼ìš” íŠ¹ì§•
- **ê°ì²´ ê°ì§€**: í…ìŠ¤íŠ¸ ì˜ì—­ íƒì§€
- **ë°”ìš´ë”© ë°•ìŠ¤**: ì¢Œí‘œ ì •ë³´ ë°˜í™˜
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ë¹ ë¥¸ ì¶”ë¡  ì†ë„

### êµ¬í˜„ ìœ„ì¹˜
- `services/yolo_service.py`: YOLO ëª¨ë¸ ì„œë¹„ìŠ¤
- `routers/yolo.py`: YOLO API ì—”ë“œí¬ì¸íŠ¸

---

### êµ¬í˜„ ì½”ë“œ

**íŒŒì¼**: `services/yolo_service.py`

```python
def detect_text_regions(image_url: str) -> List[Dict]:
    """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€"""
    # 1. ì´ë¯¸ì§€ ë¡œë“œ
    image = load_image_from_url(image_url)
    
    # 2. YOLO ëª¨ë¸ ì‹¤í–‰
    results = yolo_model(image)
    
    # 3. ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
    text_regions = []
    for result in results:
        boxes = result.boxes
        for box in boxes:
            text_regions.append({
                'x1': int(box.xyxy[0][0]),
                'y1': int(box.xyxy[0][1]),
                'x2': int(box.xyxy[0][2]),
                'y2': int(box.xyxy[0][3]),
                'confidence': float(box.conf[0])
            })
    
    return text_regions
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ: í…ìŠ¤íŠ¸ ë°°ì¹˜ ìœ„ì¹˜ ê²°ì •ì— í™œìš©
- ì‹ ë¢°ë„ ì ìˆ˜: ë‚®ì€ ì‹ ë¢°ë„ ì˜ì—­ì€ ì œì™¸ ê°€ëŠ¥

---

## 3ï¸âƒ£ GPT í†µí•©

### ëª©ì 
í…ìŠ¤íŠ¸ ìƒì„± ë° ë³€í™˜ (í•œêµ­ì–´â†”ì˜ì–´, ê´‘ê³ ë¬¸êµ¬ ìƒì„±, í”¼ë“œ ê¸€ ìƒì„±)

### ì£¼ìš” íŠ¹ì§•
- **ë‹¤ì–‘í•œ ì‘ì—… ì§€ì›**: ë²ˆì—­, ìƒì„±, ë³€í™˜
- **LLM ì¶”ì **: ëª¨ë“  í˜¸ì¶œì„ `llm_traces` í…Œì´ë¸”ì— ì €ì¥
- **í† í° ëª¨ë‹ˆí„°ë§**: ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ë¹„ìš© ê´€ë¦¬

### êµ¬í˜„ ìœ„ì¹˜
- `services/gpt_service.py`: GPT ì„œë¹„ìŠ¤ ë¡œì§
- `routers/gpt.py`: GPT API ì—”ë“œí¬ì¸íŠ¸
- `routers/instagram_feed.py`: ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±

---

### êµ¬í˜„ ì½”ë“œ

#### 1. GPT ì„œë¹„ìŠ¤

**íŒŒì¼**: `services/gpt_service.py`

```python
def translate_eng_to_kor(text: str, llm_model_id: str) -> Dict[str, Any]:
    """ì˜ì–´ â†’ í•œê¸€ ë³€í™˜"""
    from openai import OpenAI
    from database import SessionLocal
    from sqlalchemy import text
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    # 1. GPT API í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a translator..."},
            {"role": "user", "content": f"Translate to Korean: {text}"}
        ],
        temperature=0.7
    )
    
    # 2. í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
    usage = response.usage
    prompt_tokens = usage.prompt_tokens if usage else None
    completion_tokens = usage.completion_tokens if usage else None
    total_tokens = usage.total_tokens if usage else None
    
    # 3. LLM Trace ì €ì¥
    db = SessionLocal()
    try:
        llm_trace_id = uuid.uuid4()
        db.execute(text("""
            INSERT INTO llm_traces (
                llm_trace_id, job_id, llm_model_id,
                provider, operation_type,
                request, response,
                prompt_tokens, completion_tokens, total_tokens,
                token_usage, latency_ms,
                created_at, updated_at
            ) VALUES (
                :llm_trace_id, :job_id, :llm_model_id,
                'gpt', 'eng_to_kor',
                :request, :response,
                :prompt_tokens, :completion_tokens, :total_tokens,
                :token_usage, :latency_ms,
                CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
            )
        """), {
            "llm_trace_id": llm_trace_id,
            "job_id": job_id,
            "llm_model_id": llm_model_id,
            "request": json.dumps({"text": text}),
            "response": json.dumps({"translated_text": response.choices[0].message.content}),
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "token_usage": json.dumps({
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            }) if usage else None,
            "latency_ms": latency
        })
        db.commit()
    finally:
        db.close()
    
    return {
        "translated_text": response.choices[0].message.content,
        "llm_trace_id": str(llm_trace_id)
    }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  í˜¸ì¶œì„ `llm_traces`ì— ì €ì¥
- **í† í° ëª¨ë‹ˆí„°ë§**: ë¹„ìš© ê´€ë¦¬ ë° ìµœì í™”
- **ì—ëŸ¬ ì²˜ë¦¬**: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì ì ˆí•œ ì²˜ë¦¬

---

#### 2. ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ìƒì„±

**íŒŒì¼**: `routers/instagram_feed.py`

```python
@router.post("", response_model=InstagramFeedOut)
def create_instagram_feed(body: InstagramFeedIn, db: Session = Depends(get_db)):
    """ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê¸€ ìƒì„±"""
    
    # 1. Job ì¡°íšŒ
    job = db.query(Job).filter(Job.job_id == body.job_id).first()
    
    # 2. í•„ìš”í•œ ë°ì´í„° ì¡°íšŒ
    ad_copy_kor = get_ad_copy_kor_from_job(job.job_id, db)
    store_info = get_store_info_from_job(job.job_id, db)
    
    # 3. GPT API í˜¸ì¶œ
    result = gpt_service.generate_instagram_feed(
        ad_copy_kor=ad_copy_kor,
        store_info=store_info,
        gpt_prompt=body.gpt_prompt,
        llm_model_id=body.llm_model_id
    )
    
    # 4. LLM Trace ì €ì¥
    llm_trace_id = result["llm_trace_id"]
    
    # 5. Instagram Feed ì €ì¥
    instagram_feed = InstagramFeed(
        instagram_feed_id=uuid.uuid4(),
        job_id=job.job_id,
        llm_trace_id=llm_trace_id,
        gpt_prompt=body.gpt_prompt,
        ad_copy_kor=ad_copy_kor,
        instagram_ad_copy=result["feed_text"],
        hashtags=result["hashtags"]
    )
    db.add(instagram_feed)
    db.commit()
    
    return instagram_feed
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **SNS ìµœì í™”**: ì¸ìŠ¤íƒ€ê·¸ë¨ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ìƒì„±
- **í•´ì‹œíƒœê·¸ ìë™ ìƒì„±**: ê´€ë ¨ í•´ì‹œíƒœê·¸ ìë™ ì¶”ì¶œ
- **ì™„ì „í•œ ì¶”ì **: ëª¨ë“  ìƒì„± ê³¼ì • ì¶”ì 

---

### íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

#### ë¬¸ì œ 1: í† í° ì‚¬ìš©ëŸ‰ì´ null

**ì¦ìƒ**: `llm_traces` í…Œì´ë¸”ì˜ í† í° ê´€ë ¨ ì»¬ëŸ¼ì´ null

**ì›ì¸**: OpenAI API ì‘ë‹µì— `usage` ì •ë³´ê°€ ì—†ìŒ

**í•´ê²° ë°©ë²•**:
```python
# usage ì •ë³´ í™•ì¸
if response.usage:
    prompt_tokens = response.usage.prompt_tokens
    completion_tokens = response.usage.completion_tokens
    total_tokens = response.usage.total_tokens
else:
    logger.warning("OpenAI API ì‘ë‹µì— usage ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
```

---

#### ë¬¸ì œ 2: API í˜¸ì¶œ ì‹¤íŒ¨

**ì¦ìƒ**: OpenAI API í˜¸ì¶œ ì‹¤íŒ¨

**í•´ê²° ë°©ë²•**:
1. API í‚¤ í™•ì¸
2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
3. Rate limit í™•ì¸
4. ì¬ì‹œë„ ë¡œì§ êµ¬í˜„

---

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

### LLaVA
- âœ… ë©€í‹°ëª¨ë‹¬ AI í™œìš© (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)
- âœ… Thread-safe ëª¨ë¸ ë¡œë”©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
- âœ… 8-bit ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ

### YOLO
- âœ… ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€
- âœ… í…ìŠ¤íŠ¸ ë°°ì¹˜ ìµœì í™”

### GPT
- âœ… ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìƒì„± ì‘ì—… ì§€ì›
- âœ… ì™„ì „í•œ LLM í˜¸ì¶œ ì¶”ì 
- âœ… í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

---

## ğŸ“Š ì„±ëŠ¥ ë° í†µê³„

### LLaVA
- **ëª¨ë¸ ë¡œë”© ì‹œê°„**: ì•½ 1-2ë¶„ (ìµœì´ˆ 1íšŒ)
- **ì¶”ë¡  ì‹œê°„**: ì•½ 5-10ì´ˆ (ì´ë¯¸ì§€ë‹¹)
- **GPU ë©”ëª¨ë¦¬**: ì•½ 10-15GB (8-bit ì–‘ìí™” ì‹œ ì•½ 5-8GB)

### YOLO
- **ì¶”ë¡  ì‹œê°„**: < 1ì´ˆ (ì´ë¯¸ì§€ë‹¹)
- **ì •í™•ë„**: ë†’ì€ ì‹ ë¢°ë„ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€

### GPT
- **API ì‘ë‹µ ì‹œê°„**: ì•½ 2-5ì´ˆ (ì‘ì—…ì— ë”°ë¼ ë‹¤ë¦„)
- **í† í° ì‚¬ìš©ëŸ‰**: ì‘ì—…ë‹¹ í‰ê·  500-1000 í† í°

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- `DOCS_OCR_IMPLEMENTATION.md`: OCR êµ¬í˜„ ë¬¸ì„œ
- `test/README_THREAD_SAFE_TEST.md`: Thread-safe ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
- `DOCS_JS_PART_IMPLEMENTATION.md`: JS íŒŒíŠ¸ êµ¬í˜„ ê°€ì´ë“œ
- `DOCS_YH_PART_IMPLEMENTATION.md`: YH íŒŒíŠ¸ êµ¬í˜„ ê°€ì´ë“œ

---

**ì‘ì„±ì¼**: 2025-12-02  
**ì‘ì„±ì**: LEEYH205  
**ë²„ì „**: 1.0.0

