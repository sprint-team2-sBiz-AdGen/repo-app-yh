# Thread-safe ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## ê°œìš”

ì—¬ëŸ¬ variantsê°€ ë™ì‹œì— ì‹¤í–‰ë  ë•Œ LLaVA ëª¨ë¸ì´ í•œ ë²ˆë§Œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.

## í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘ (thread-safe ë¡œë”© ì ìš© í™•ì¸)

```bash
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘
docker-compose restart yh

# ì¬ì‹œì‘ í™•ì¸
docker logs feedlyai-work-yh --tail 20
```

### 2. Variants ìƒì„± ë° ë™ì‹œ íŠ¸ë¦¬ê±°

ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ variantsë¥¼ ìƒì„±í•˜ê³  ë™ì‹œì— íŠ¸ë¦¬ê±°:

```bash
# 3ê°œ variants ìƒì„± ë° íŠ¸ë¦¬ê±°
python3 test/test_job_variants_pipeline.py --jobs 1 --variants-per-job 3
```

ë˜ëŠ” ë” ë§ì€ variantsë¡œ í…ŒìŠ¤íŠ¸:

```bash
# 5ê°œ variantsë¡œ í…ŒìŠ¤íŠ¸
python3 test/test_job_variants_pipeline.py --jobs 1 --variants-per-job 5
```

### 3. ëª¨ë¸ ë¡œë”© íšŸìˆ˜ í™•ì¸

íŠ¸ë¦¬ê±° í›„ ì¼ì • ì‹œê°„(ì˜ˆ: 2-3ë¶„) ëŒ€ê¸°í•œ í›„ ë¡œê·¸ í™•ì¸:

```bash
# Docker ë¡œê·¸ì—ì„œ ì§ì ‘ í™•ì¸
docker logs feedlyai-work-yh 2>&1 | grep -c "Loading LLaVa model"

# ë˜ëŠ” ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
docker logs -f feedlyai-work-yh 2>&1 | grep "Loading LLaVa model"
```

## ì˜ˆìƒ ê²°ê³¼

### âœ… ì„±ê³µ ì¼€ì´ìŠ¤

```
ğŸ“ˆ ì£¼ìš” ì§€í‘œ:
  - ëª¨ë¸ ë¡œë”© ì‹œì‘: 1íšŒ
  - Checkpoint ë¡œë”©: ì—¬ëŸ¬ íšŒ (ê° shard ì§„í–‰ë¥  í‘œì‹œ)
  - ëª¨ë¸ ë¡œë”© ì™„ë£Œ: 1íšŒ
  - Meta tensor ì˜¤ë¥˜: 0íšŒ

ğŸ” íŒë‹¨:
  âœ… ëª¨ë¸ ë¡œë”© ì‹œì‘ì´ 1íšŒë§Œ ë°œìƒí–ˆìŠµë‹ˆë‹¤!
     â†’ Thread-safe ë¡œë”©ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
```

### âŒ ì‹¤íŒ¨ ì¼€ì´ìŠ¤

```
ğŸ“ˆ ì£¼ìš” ì§€í‘œ:
  - ëª¨ë¸ ë¡œë”© ì‹œì‘: 3íšŒ ì´ìƒ
  - Meta tensor ì˜¤ë¥˜: ì—¬ëŸ¬ íšŒ

ğŸ” íŒë‹¨:
  âŒ ëª¨ë¸ ë¡œë”© ì‹œì‘ì´ ì—¬ëŸ¬ íšŒ ë°œìƒí–ˆìŠµë‹ˆë‹¤
     â†’ Thread-safe ë¡œë”©ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```

## ì£¼ì˜ì‚¬í•­

1. **ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘ í•„ìš”**: Thread-safe ë¡œë”© ì½”ë“œê°€ ì ìš©ë˜ë ¤ë©´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¬ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.

2. **ëª¨ë¸ ë¡œë”© ì‹œê°„**: ëª¨ë¸ ë¡œë”©ì€ ë³´í†µ 1-2ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì „ì— ì¶©ë¶„í•œ ì‹œê°„ì„ ë‘ì„¸ìš”.

3. **ë¡œê·¸ ì‹œê°„ ë²”ìœ„**: `--since` ì˜µì…˜ìœ¼ë¡œ ë¡œê·¸ í™•ì¸ ì‹œê°„ ë²”ìœ„ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

4. **Checkpoint ë¡œë”© ë©”ì‹œì§€**: "Loading checkpoint shards" ë©”ì‹œì§€ëŠ” ì—¬ëŸ¬ ë²ˆ ë‚˜íƒ€ë‚  ìˆ˜ ìˆì§€ë§Œ, ì´ëŠ” ê° shardì˜ ì§„í–‰ë¥  í‘œì‹œì¼ ë¿ ì‹¤ì œë¡œëŠ” í•œ ë²ˆë§Œ ë¡œë“œë©ë‹ˆë‹¤.

## ë¬¸ì œ í•´ê²°

### ëª¨ë¸ì´ ì—¬ëŸ¬ ë²ˆ ë¡œë“œë˜ëŠ” ê²½ìš°

1. `services/llava_service.py`ì—ì„œ `_model_lock`ì´ ì œëŒ€ë¡œ ì‚¬ìš©ë˜ê³  ìˆëŠ”ì§€ í™•ì¸
2. Double-checked locking íŒ¨í„´ì´ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ë˜ì—ˆëŠ”ì§€ í™•ì¸
3. ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì¬ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸

### Meta tensor ì˜¤ë¥˜ ë°œìƒ

1. PyTorch ë²„ì „ í™•ì¸
2. `torch.nn.Module.to_empty()` ì‚¬ìš© ì—¬ë¶€ í™•ì¸
3. ëª¨ë¸ ë¡œë”© ë¡œì§ì—ì„œ device mapping í™•ì¸

## ê´€ë ¨ íŒŒì¼

- `services/llava_service.py`: Thread-safe ëª¨ë¸ ë¡œë”© êµ¬í˜„
- `test/test_thread_safe_model_loading.py`: ì™„ì „ ìë™í™” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- `test/test_job_variants_pipeline.py`: Variants ìƒì„± ë° íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸

## ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ë°©ë²•

ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• (ì´ë¯¸ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸):

```bash
docker exec feedlyai-work-yh python3 -c "
import threading
import time
from services.llava_service import get_llava_model

results = []
lock = threading.Lock()

def request_model(thread_id):
    try:
        start_time = time.time()
        processor, model = get_llava_model()
        end_time = time.time()
        with lock:
            results.append({
                'thread_id': thread_id,
                'time': end_time - start_time,
                'model_id': id(model)
            })
            print(f'[Thread {thread_id}] ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({end_time - start_time:.2f}ì´ˆ)')
    except Exception as e:
        print(f'[Thread {thread_id}] ì˜¤ë¥˜: {e}')

threads = []
for i in range(3):
    t = threading.Thread(target=request_model, args=(i+1,))
    threads.append(t)
    t.start()

for t in threads:
    t.join()

model_ids = [r.get('model_id') for r in results if 'model_id' in r]
unique_model_ids = len(set(model_ids)) if model_ids else 0
print(f'ê³ ìœ  ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤: {unique_model_ids}ê°œ (ì˜ˆìƒ: 1ê°œ)')
"
```

